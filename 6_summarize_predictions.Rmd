---
title: "Campaign Predictions Summary"
author: "Magali Blanco"
date: ' `r Sys.time()` '
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    number_sections: true
    toc_float: true
    collapsed: false
    smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

# Setup 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=F, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 10, fig.width = 10
                      )  


# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
           detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(kableExtra,
  tidyverse, ggpubr, # ggarrange()
  GGally, # ggpairs
  ggmap, sf, ggspatial, #mapping...adding scales, N arrows
  parallel,
  pls,
  gstat # idw()
)

set.seed(1)

#functions
source("0_Functions.R")

use_cores <- 4

image_path <- file.path("..", "Manuscript", "Images")

```

```{r}
# UPLOAD DATA 

######################################################################################################
# common variables
# 3 PLS components (or could be different)
load(file.path("Data", "Output", "Objects", "pls_comp_n.rda"))
load(file.path("Data", "Output", "Objects", "pollutant_levels.rda"))
# e.g., "mean_of_win_medians"
load(file.path("Data", "Output", "Objects", "keep_averages.rda"))
 
# # monitoring 'locations' table
# load(file.path("Data", "Original", "locations_table.rda"))

########################################################################
# mapping
crs_m <- 32148

crs_deg <- 4326 #WGS84. in decimal degrees
## PROJ.4 string for crs_deg
crs_deg_proj4 <- "+proj=longlat +datum=WGS84 +no_defs"

#shapefiles
monitoring_area_shp <- readRDS(file.path("Data", "Output", "GIS", "monitoring_area_shp.rda")) %>%
  #convert from 4269 
  st_transform(crs_deg)

monitoring_land_shp <- readRDS(file.path("Data", "Output", "GIS", "monitoring_land_shp.rda"))


#ggplot(data=monitoring_land_shp) + geom_sf()

########################################################################

# mobile covariates
mm_cov0 <- read.csv(file.path("Data", "Original", "Geocovariates", "dr0311_mobile_covars.csv")) %>%
  rename(location = native_id) %>%
  mutate(location = as.character(location)) %>%
  select_if(~!any(is.na(.))) #%>% filter(!location %in% c("MS0000", "MS0601"))

# monitoring predictions
mm_predictions <- readRDS(file.path("Data", "Output", "Predictions", "monitoring_location_predictions.rda")) %>%
  filter(annual == keep_averages) %>%
  select(-c(annual)) %>%
  left_join(select(mm_cov0, location, latitude, longitude)) %>%
  mutate(residual = prediction - value) %>%
  variable_relabel(keep_original_var = T) 

mm_cov <- filter(mm_cov0, location %in% unique(mm_predictions$location) )


# grid predictions
grid_predictions0 <- readRDS(file.path("Data", "Output", "Predictions", "grid", "predictions.rda")) 

grid_predictions <- grid_predictions0 %>%  
  filter(annual == keep_averages,
         in_monitoring_area==TRUE) %>%
  select(-c(annual, in_monitoring_area)) %>%
  variable_relabel(keep_original_var = T) 

grid_predictions2 <- st_as_sf(grid_predictions, coords = c("longitude", "latitude"),  remove = F, crs=crs_deg)  


# # for QGIS
# grid_predictions0 %>%
#   filter(annual == keep_averages) %>%
#   select(-contains(c("key", "msa", "native_id", "annual"))) %>%
#   spread(variable, prediction) %>%  
#   st_as_sf(., coords = c("longitude", "latitude"),  remove = F, crs=crs_deg) %>%
#   st_write(., file.path("Data", "Output", "Predictions", "grid", "monitoring_predictions.shp"),
#          #delete file if already exists
#            delete_layer=TRUE)




# grid covariates
grid_cov <- readRDS(file.path("Data", "Original", "Geocovariates", "dr0311_grid_covars.rda") )

# PLS U& variogram models from the training-validation dataset fit while predicting at test locations
train_validation_models <- readRDS(file.path("Data", "Output", "Predictions", "train_validation_models.rda"))


# model performance
model_performance <- read.csv(file.path("Data", "Output", "Predictions", "model_performance.csv"))

```


```{r}
#need bbox w/ lat/long coordinates
bbox <- st_bbox(st_transform(st_buffer(st_transform(monitoring_area_shp, crs_m), 10000), crs_deg))

names(bbox) <- c("left", "bottom", "right", "top")

map0 <- suppressMessages(get_stamenmap(
  bbox = bbox, 
  zoom = 11, 
  maptype = "toner-lite" #has airport symbol
  #maptype = "toner-background" #roads & water but no airport
))

## map labels
map_x_labels <- c(seq(-122.5, -121.9, 0.2)) #0.2
map_y_labels <- c(seq(47.2, 48, 0.2)) #%>% format(nsmall=1)




unique_pollutants <- unique(grid_predictions2$variable) %>% sort()

non_ufp_p <- str_subset(string =  unique_pollutants, pattern = "PNC", negate = T) %>% sort()

ufp_p <- str_subset(string =  unique_pollutants, pattern = "PNC", negate = F) %>% sort()

unique_pollutants0 <- distinct(grid_predictions, variable, var0) %>%
  arrange(variable) %>%
  pull(var0)

# secondary PNC instruments
secondary_instruments0 <- c("pnc_screen", "ns_total_conc", "pmdisc_number")

# primary instruments only include one PNC instrument 
primary_instruments0 <- setdiff(unique_pollutants0, secondary_instruments0)


```

```{r}
# common variables
original_var_labels <- unique(mm_predictions$var0)

cov_names <- select(mm_cov, m_to_a1:last_col()) %>% names()


```

```{r}
# Lasso fn runs a lasso regression model and returns a list: a) covariate estimates: b) lambda

lasso_fn <- function(dt, x_names, y_name, family. = "gaussian", lambda. = "") {
  
  pacman::p_load(glmnet)
  
  x <- model.matrix(as.formula(paste(y_name, "~", 
                                     paste(x_names, collapse = " + "))
  ), dt)[, -1]
  
  #replace y "name" w/ actual data
  y <- dt[[y_name]]   
  
  #select lambda through CV if not supplied
  if(lambda. == ""){
    cv.out <- cv.glmnet(x = x,
                        y = y, 
                        alpha=1, 
                        family= family., 
                        standardize=T)
    
    lambda. <- cv.out$lambda.min
  }
  
  # run Lasso
  lasso.m <- glmnet(x = x,
                    y = y, 
                    alpha = 1, 
                    family= family.,  
                    standardize = T)
  
  #save coefficient estimates
  lasso_coef <- predict(lasso.m, 
                        type= "coefficients",  
                        s= lambda.)[1:(ncol(x)+1),] %>%
    as.data.frame() %>%
    rownames_to_column() %>%
    rename(cov = rowname,
           coef = ".") %>%
    #keep coefficients that are not 0 or intercept values
    filter(coef != 0,
           cov != "(Intercept)")
  
  
  results <- list(results = lasso_coef,
                  lambda = lambda.
  )
  
  return(results)
  
}
```


# PLS Model Specifics 

```{r}
 
# function labels covariates 

split_cov_name <- function(dt, cov) {
  dt <- suppressWarnings(dt %>%
                           rename(cov_full_name = cov) %>%
                           mutate(
                             Buffer = substr(cov_full_name, nchar(cov_full_name)-4, nchar(cov_full_name)),
                             #for non-buffered covariates, use "0"
                             Buffer = as.numeric(ifelse(!is.na(as.integer(Buffer)), Buffer, 0)),
                             #drop buffer repetition
                             cov = ifelse(Buffer==0, cov_full_name, substr(cov_full_name, 1, nchar(cov_full_name)-5) )
                           )
  ) %>%
    select(contains("cov"), Buffer, everything())
  
  # elevation
  dt$cov[grepl("^elev_.+_above$", dt$cov_full_name)] <- "elev_above"
  dt$cov[grepl("^elev_.+_below$", dt$cov_full_name)] <- "elev_below"
  dt$cov[grepl("^elev_.+_stdev$", dt$cov_full_name)] <- "elev_stdev"
  dt$cov[grepl("^elev_.+_at_elev$", dt$cov_full_name)] <- "elev_at_elev"
  
  dt$Buffer[grepl("_1k_", dt$cov_full_name)] <- 1000
  dt$Buffer[grepl("_5k_", dt$cov_full_name)] <- 5000
  
  return(dt)
}

```

```{r}

# variance explained
lapply(train_validation_models, function(x) {
  pls_model = x$pls_model
  total_variance_expl = sum(explvar(pls_model)) %>% round()
  print(paste0("variance explained: ", x$variable, ": ", total_variance_expl, "%"))
  
})

```

```{r}
all_pls_loadings <- lapply(train_validation_models, function(x) {
  #x = train_validation_models[1]
  pls_model = x$pls_model
  
  pls_loadings0 = pls_model$loadings[,1:pls_comp_n] %>% as.data.frame() %>%
    rownames_to_column(var="cov")
  names(pls_loadings0) <- make.names(names(pls_loadings0))
  
  pls_loadings <- pls_loadings0 %>%
    split_cov_name() %>%
    #make long format for faceting
    gather(key = "Component", value = "Loading", contains("Comp")) %>%
    mutate(Component = as.numeric(substr(Component, nchar(Component), nchar(Component))),
           variable = x$variable
           )
  
  return(pls_loadings)
  
  }) %>%
  bind_rows()  %>%
  variable_relabel() 

```

covariates with largest loadings

```{r}
# table
all_pls_loadings %>%
  filter(Component ==1) %>%
  group_by(variable, ufp_range_nm) %>% 
  arrange(desc(abs(Loading))) %>%  
  slice(1:30) %>% 
  distinct(cov, variable, ufp_range_nm) %>%
  kable(caption = "covariates in Comp.1 with largest loadings") %>%
  kable_styling()




# PLOT
print("PLS component loadings")

all_pls_loadings  %>%
  #only show P-TRAK PNC instrument
  filter(!(grepl("PNC", variable) & ufp_instrument != "P-TRAK")) %>%  
  mutate(
    variable = factor(variable, levels = pollutant_levels2)
  ) %>%
  ggplot(aes(x = Loading, y = cov)) +
  geom_vline(xintercept=0, linetype=2, alpha=0.5) +
  geom_point(aes(size=Buffer, col=variable), shape=1, alpha=0.7) +
  facet_grid(~Component, labeller = "label_both") +
  labs(y = "Geocovariate",
       size = "Buffer (m)",
       col = "Pollutant"#,
       ) +
  theme(legend.position = "right") 

ggsave(file.path(image_path, "SI", "pls_loadings.png"), width = 8, height = 11)


```


# Prediction 

## Scatterplots: estimates vs predictions

```{r, fig.height = 12}
mm_predictions %>%
  variable_relabel(var = "var0") %>% 
  ggplot(aes(x=value, y=prediction)) +
  facet_wrap_equal(~variable+ufp_instrument, scales="free") + 
  geom_abline(slope = c(1, 0.75, 1.25), intercept = 0, alpha=0.2, linetype=2) +
  geom_label(aes(x=Inf, y=Inf, label = "1-1"), vjust = "inward", hjust = "inward") +
  geom_point(alpha=0.3) + 
  geom_smooth(method = "lm", se=F) +
  theme(aspect.ratio = 1) + 
  labs(x = "Estimate", y= "Prediction")
  
ggsave(file.path(image_path, "SI", "scatter_plot.png"), width = 8, height = 8)

```


```{r}

# summarize model performance

model_performance %>%
  filter(annual %in%  c(keep_averages,
                        "mean_of_medians",
                        "median_of_medians"
                        )) %>%
  mutate(
    annual = recode_factor(annual,
                           "mean_of_win_medians" = "mean of winsorized medians",
                           "mean_of_medians" = "mean of medians",
                           "median_of_medians" = "median of medians",
                           ),
      
    RMSE = ifelse(RMSE >=10, round(RMSE), round(RMSE, 1)),
    RMSE = as.character(RMSE)
  ) %>%
  variable_relabel() %>%
   select(-c(#annual, 
            no_sites, reg_based_R2, ufp_range_nm)) %>%
   
  arrange(annual, variable, out_of_sample) %>%
  
  kable(caption = "Model performances for annual mean of medians concentrations. N=278 for cross-validation set; N=31 for test set.",
        col.names = c("Pollutant", "Annual Average", 
                      "Out-of-Sample Set", "RMSE", "MSE-based R2", "UFP Instrument")
  ) %>%
  kable_styling()


```


sensitivity analyses

```{r}
rmse_t <- model_performance %>% 
  filter(annual %in%  c(keep_averages, "mean_of_medians", "median_of_medians")) %>%
  mutate(annual = paste0(annual, "_rmse")) %>%
  select(variable, annual, out_of_sample, RMSE) %>%
  mutate(
    RMSE = ifelse(RMSE >=10, round(RMSE), round(RMSE, 1)),
    RMSE = as.character(RMSE) 
    # RMSE = format(RMSE, big.mark = ","),
    # RMSE = gsub(".0", "", RMSE)
  ) %>%
  spread(annual, RMSE)
  
model_performance %>% 
  filter(annual %in%  c(keep_averages, "mean_of_medians", "median_of_medians")) %>%
  mutate(annual = paste0(annual, "_r2")) %>%
  select(variable, annual, out_of_sample, MSE_based_R2) %>%
  spread(annual, MSE_based_R2) %>%
  left_join(rmse_t) %>%
  mutate(
    out_of_sample = recode_factor(out_of_sample,
                                  "cross-validation" = "CV",
                                  "test" = "Test"
                                  )
  ) %>%
  variable_relabel() %>%
  select(variable, ufp_instrument, out_of_sample, 
         mean_of_win_medians_r2, mean_of_medians_r2, median_of_medians_r2,
         mean_of_win_medians_rmse, mean_of_medians_rmse, median_of_medians_rmse
         ) %>%
  arrange(variable, ufp_instrument, out_of_sample) %>%
  
  kable(caption = "Model performances for annual mean of medians concentrations. N=278 for cross-validation set; N=31 for test set.",
        col.names = c(rep(" ", 3),  
                      "Mean of Winsorized Medians", "Mean of Medians","Median of Medians",
                      "Mean of Winsorized Medians", "Mean of Medians","Median of Medians"
                      )
        ) %>%
  kable_styling() %>%
  add_header_above(c("Pollutant" =2, "OOS", "MSE-based R2"=3, "RMSE"=3))
  
```



# Grid Predictions 

## Interpolate Predictions to a Finer Grid

```{r}
# helpful tutorial: https://swilke-geoscience.net/post/spatial_interpolation/

grid_resolution <- 0.003
grid_idp <- 1.5 
grid_nmax <- 10

idw_file <- file.path("Data", "Output", "Predictions", "grid", paste0("pred_idw_res", grid_resolution, "_idp", grid_idp, "_nmax", grid_nmax, ".rda"))

# create a finer interpolated grid with the desired attributes (above) if one does not already exist
if(!file.exists(idw_file)){
  
  # 1. create a finer grid
  finer_grid <- st_as_sf(grid_predictions0, coords = c("longitude", "latitude"),  crs= crs_deg) %>%
    # make a rectangular box w/ evenly spaced points at ~500 m resolution
    st_bbox() %>% st_as_sfc() %>%
    st_make_grid(cellsize = grid_resolution, what = "centers") %>% 
    # view in df format
    st_as_sf()  
    
  # 2. interpollate to the finer grid 
  idw_df0 <- lapply(unique_pollutants0, function(x) {
     
    idw_result = idw(formula = prediction~1,  
            locations = st_as_sf(filter(grid_predictions0, variable ==x), coords = c("longitude", "latitude"),  remove = F, crs= crs_deg), 
            newdata = finer_grid,  
            #smaller inverse distnace powers produce more smoothing (i.e., give points furthewr away larger weights). default is the max, 2.0.
            idp=grid_idp, 
            # how many nearby points should be used to smooth
            nmax=grid_nmax #maxdist=0.1
            ) %>%
      mutate(variable = x) 
    }) %>%
    bind_rows() %>% 
    cbind(., st_coordinates(.)) %>%
    variable_relabel(keep_original_var = T)
  
  # ggplot(data=idw_df0) + geom_raster(aes(x=X, y=Y, fill=var1.pred), interpolate = T) +
  #   geom_sf(data=monitoring_land_shp, inherit.aes = F, alpha=0) 
  
  # 3. only keep predictions in monitoring region & not in water
  idw_df <- st_intersection(idw_df0, monitoring_land_shp)
  
  # 4. save file
  saveRDS(idw_df, idw_file)
  
} else {
  # if file already exists, read it in
    idw_df <- readRDS(idw_file)
  }
            
```


## Prediction Maps 


```{r, prediction maps, fig.height = 12}
# 4. plot predictions as a raster

lapply(primary_instruments0, function(x) {
  
  ggmap(ggmap = map0, darken = c(.5, "white")) +
    #predictions
    geom_raster(data= filter(idw_df, var0 == x), inherit.aes = F, 
                aes(fill=var1.pred, x=X, y=Y), interpolate = T)  +
           geom_sf(data=monitoring_land_shp, inherit.aes = F, alpha=0, size=0.1) +
           scale_fill_gradient(name = "Conc", low = "yellow", high = "red") +
    facet_wrap(~variable)  +
    # add scales & N arrow 
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr", pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering) +
    theme_bw() +
    theme(
      legend.justification=c(0,1),  
      legend.position=c(0,1),  
      legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels,
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                       )
    ) +
    #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3, 
                  label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."), size=2.5,
    ) +
    labs(x = "Longitude",
         y = "Latitude" 
    ) 
  }) %>%
  ggarrange(plotlist = .)
  
   
ggsave(file.path(image_path, paste0("prediction_map_idp", grid_idp, ".png")),  height = 13, width = 13)
 
```

```{r, SI PNC prediction maps, fig.height = 12}
# all PNC instruments 

lapply(c("pnc_noscreen", secondary_instruments0), function(x) {

  ggmap(ggmap = map0, darken = c(.5, "white")) +
    #predictions
    geom_raster(data= filter(idw_df, var0 == x), inherit.aes = F, 
                aes(fill=var1.pred, x=X, y=Y),
                interpolate = T)  +
           geom_sf(data=monitoring_land_shp, inherit.aes = F, alpha=0, size=0.1) +
           scale_fill_gradient(name = "Conc", low = "yellow", high = "red") +
    facet_wrap(~variable+ufp_instrument)  +
    # add scales & N arrow 
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr", pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering) +
    theme_bw() +
    theme(
      legend.justification=c(0,1),  
      legend.position=c(0,1),  
      legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels,
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                       )
    ) +
    #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3, 
                  label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."), size=2.5,
    ) +
    labs(x = "Longitude",
         y = "Latitude" 
    ) 
  }) %>%
  ggarrange(plotlist = .)

ggsave(file.path(image_path, "SI", paste0("prediction_map_pnc_idp", grid_idp, ".png")),  height = 13, width = 11)

```



```{r, same legend for PNC, fig.height = 12, eval=F}

## secondary, PNC instruments

ggmap(ggmap = map0, darken = c(.5, "white")) +
  geom_raster(data=filter(idw_df, variable %in% ufp_p), inherit.aes = F, 
              aes(fill=var1.pred, x=X, y=Y))  +
  
  geom_sf(data=monitoring_land_shp, inherit.aes = F, alpha=0, size=0.1) +
  scale_fill_gradient(name = "Conc", low = "yellow", high = "red",
                      #reduce the discmini's influence on the scale
                      trans = "sqrt", #"sqrt" #"log10",
                      breaks = c(3e3, 10e3, 20e3)
                      ) +
  
  
  facet_wrap(~variable+ufp_range_nm, nrow = 2)  + 
  # add scale & N arrow to top rught
  annotation_scale(location = "tr") +
  annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +
  
  annotation_north_arrow(location = "tr", pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank(),
  ) +
  coord_sf(expand = F) +
  scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
  scale_y_continuous(breaks = map_y_labels, 
                     labels = format(map_y_labels,digits = 1, nsmall = 1)
  ) +
  #add attribution/reference 
  geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
  ), size=2.5) +
  labs(x = "Longitude", y = "Latitude", fill = "") 

ggsave(file.path(image_path, paste0("map_ufp_idp", grid_idp, ".png")),  height = 13, width = 11)

```

 

# Correlations

```{r}

cor_df <- mm_predictions %>%
  mutate(
  pollutant = if_else(grepl("PNC", variable),
                      paste0(variable, "\n", ufp_instrument),
                      as.character(variable)
  )
  ) %>%    
  select(pollutant, location, prediction) %>%
  spread(pollutant, prediction) %>%  
  #select(contains(c("PNC", "BC", "NO2", "PM2.5", "CO2")))
  select(contains(c("P-TRAK", "NanoScan", "DiSCmini", "BC", "NO2", "PM2.5", "CO2")))

#cor_df

```

```{r}

#function colors upper panel by correlation value
# source: https://stackoverflow.com/questions/45873483/ggpairs-plot-with-heatmap-of-correlation-values 

color_cor <- function(data, mapping, method="p", use="pairwise", alpha=0.5, ...){
  #GGally, #ggpairs()
  pacman::p_load(GGally)
  
  # grab data
  x <- eval_data_col(data, mapping$x)
  y <- eval_data_col(data, mapping$y)
  
  # calculate correlation
  corr <- cor(x, y, method=method, use=use)
  
  # calculate colour based on correlation value
  # Here I have set a correlation of minus one to blue, 
  # zero to white, and one to red 
  # Change this to suit: possibly extend to add as an argument of `my_fn`
  colFn <- colorRampPalette(c("blue", "white", "red"), interpolate ='spline')
  fill <- colFn(100)[findInterval(corr, seq(-1, 1, length=100))]
  
  ggally_cor(data = data, mapping = mapping, 
             #don't include stars if correlations "sign"
             stars = FALSE,
             digits=2,
             ...) + 
    theme_void() +
    theme(panel.background = element_rect(fill=alpha(fill, alpha)))
}
 
```

plot 

```{r}
print("Annual average pollutant prediction correlations")

# correlation plot
ggpairs(cor_df, 
        upper = list(continuous = color_cor),
        lower = list(continuous = wrap("smooth_loess", alpha=0.2))) +  
  scale_x_continuous(guide = guide_axis(check.overlap = TRUE))

ggsave(file.path(image_path, "SI", "prediction_correlations.png"), height = 11, width = 11)

 
```

# Prediction Errors

### maps - where are the large errors

```{r, fig.height = 12}

#non-ufp
lapply(non_ufp_p, function(i) {
  #i== non_ufp_p[1]
  ggmap(ggmap = map0, darken = c(.5, "white")) +
      geom_point(data=filter(mm_predictions, variable == i), aes(x=longitude, y=latitude, col=residual)) + 
      facet_wrap(~variable) + 
      scale_color_gradient2(name = "Conc", low = "blue", high = "red", ) + 
    labs(title = "model residuals (prediction - estimate)")
  }) %>%
  ggarrange(plotlist = .)

# ufp
lapply(ufp_p, function(i) {
  ggmap(ggmap = map0, darken = c(.5, "white")) +
      geom_point(data=filter(mm_predictions, variable == i), aes(x=longitude, y=latitude, col=residual)) + 
      facet_wrap(~variable+ufp_instrument) + 
      scale_color_gradient2(name = "Conc", low = "blue", high = "red") +
    labs(title = "model residuals (prediction - estimate)")
  }) %>%
  ggarrange(plotlist = .)

```

### Lasso - Error predictors


```{r}

lasso_results <- lapply(original_var_labels, function(x) {
  # x=original_var_labels[2]
  lm <- filter(mm_predictions, var0==x) %>%
    left_join(mm_cov[,c("location", cov_names)]) %>% #View() 
    lasso_fn(dt = ., x_names = cov_names,  y_name = "residual")
  
  result <- lm$results %>%
    mutate(variable = x)
  }) %>%
  bind_rows()

```



```{r, fig.height = 12}
lasso_results %>%
   variable_relabel() %>%  
  ggplot(aes(x=coef, y=cov, col=ufp_instrument)) + 
  facet_wrap(~variable, scales = "free") +
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  geom_point() + 
  labs(col = "PNC Instrument")
  
```

Land use features

* where are the places that stand out?

 
```{r, fig.height=12}
#show were variables that stand out are
vars <-c("bus_s01000", 
         #ufp
         "lu_mix_barren_p10000", "lu_mine_p00050",
         #bc
         "rlu_crop_p00400", "lu_shrub_p00750",
         #no2
         "lu_wetland_p10000", 
         #co2
         "lu_nf_wetland_p15000")

lapply(vars, function(x) {
  # x = vars[1]
  ggplot(grid_cov, aes(x=longitude, y=latitude, col=!!as.symbol(x))) +
    geom_point() +
    geom_sf(data=monitoring_area_shp, inherit.aes = F, show.legend = F,
            aes(fill = "Monitoring Area"), alpha=0, lwd = 1) +
    theme(legend.position = "bottom")
  }) %>%
  ggarrange(plotlist = .)

 
  
  
```


## Compare UFP instruments

where are UFP instrument readigns the most different? Looking at estimates (not predictions) here

```{r}
diff_df <- mm_predictions %>%
  filter(grepl("PNC", variable)) %>%
  select(location, latitude, longitude, var0, value) %>%
  spread(var0, value) %>%
  mutate(
    dm_minus_ns = pmdisc_number - ns_total_conc,
    dm_minus_ptrak = pmdisc_number - pnc_noscreen,
    dm_minus_ptrak_screen = pmdisc_number - pnc_screen,
    ) %>%
  select(location, latitude, longitude, contains("dm_")) %>%
  gather(variable, value, contains("dm_"))


ufp_diff_lasso <- lapply(group_split(diff_df, variable), function(x) {
  #x = group_split(diff_df, variable)[[1]]
  
  lm <- left_join(x, mm_cov[,c("location", cov_names)]) %>%
    lasso_fn(dt = ., x_names = cov_names,  y_name = "value")
  
  lm$result %>%
    mutate(variable = first(x$variable))
  }) %>%
  bind_rows()


```

```{r}
ufp_diff_lasso %>%
  split_cov_name() %>%
  ggplot(aes(x=coef, y=cov, col=variable, size=Buffer)) + 
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  geom_point(shape=1) + 
  labs(title = "Predictors of differences in PNC instruments")
  


```

```{r}

ggmap(ggmap = map0, darken = c(.5, "white")) +
      geom_point(data=diff_df, aes(x=longitude, y=latitude, col=value)) + 
      facet_wrap(~variable) + 
      scale_color_gradient2(name = "Conc", low = "blue", high = "red", ) + 
    labs(title = "PNC estimate differences")

diff_df %>%
  group_by(variable) %>%
  summarize(
    min = min(value),
    q05 = quantile(value, 0.05),
    mean = mean(value),
    median = median(value),
    q95 = quantile(value, 0.95),
    max = max(value)
  )

```

 