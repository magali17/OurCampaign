---
title: "Prediction Summary"
author: "Magali Blanco"
date: ' `r Sys.time()` '
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    number_sections: true
    toc_float: true
    collapsed: false
    smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

# Setup 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=F, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 10, fig.width = 10
                      )  


# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
           detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(kableExtra,
  tidyverse, ggpubr, # ggarrange()
  GGally, # ggpairs
  ggmap, sf, ggspatial, #mapping...adding scales, N arrows
  parallel,
  pls
)

set.seed(1)

#functions
source("0_Functions.R")

use_cores <- 4

image_path <- file.path("..", "Manuscript", "Images")

```

```{r}
# UPLOAD DATA 

######################################################################################################
# common variables
# 3 PLS components (or could be different)
load(file.path("Data", "Output", "Objects", "pls_comp_n.rda"))
load(file.path("Data", "Output", "Objects", "pollutant_levels.rda"))
# e.g., "mean_of_wind_medians"
load(file.path("Data", "Output", "Objects", "keep_averages.rda"))
# #TEST
# keep_averages <- "median_of_medians"

# # monitoring 'locations' table
# load(file.path("Data", "Original", "locations_table.rda"))

# mobile covariates
mm_cov0 <- read.csv(file.path("Data", "Original", "Geocovariates", "dr0311_mobile_covars.csv")) %>%
  rename(location = native_id) %>%
  mutate(location = as.character(location)) %>%
  select_if(~!any(is.na(.))) #%>% filter(!location %in% c("MS0000", "MS0601"))

# monitoring predictions
mm_predictions <- readRDS(file.path("Data", "Output", "Predictions", "monitoring_location_predictions.rda")) %>%
  filter(annual == keep_averages) %>%
  select(-c(annual)) %>%
  left_join(select(mm_cov0, location, latitude, longitude)) %>%
  mutate(residual = prediction - value) %>%
  variable_relabel(keep_original_var = T) 

mm_cov <- filter(mm_cov0, location %in% unique(mm_predictions$location) )


# grid predictions
grid_predictions <- readRDS(file.path("Data", "Output", "Predictions", "grid", "grid_predictions.rda")) %>%  
  filter(annual == keep_averages,
         in_monitoring_area==TRUE) %>%
  select(-c(annual, in_monitoring_area)) %>%
  variable_relabel() 

# grid covariates
grid_cov <- readRDS(file.path("Data", "Original", "Geocovariates", "dr0311_grid_covars.rda") )

# PLS U& variogram models from the training-validation dataset fit while predicting at test locations
train_validation_models <- readRDS(file.path("Data", "Output", "Predictions", "train_validation_models.rda"))

######################################################################################################
# mapping
crs_m <- 32148
crs_deg <- 4326 #WGS84. in decimal degrees

#shapefiles
monitoring_area_shp <- readRDS(file.path("Data", "Output", "GIS", "monitoring_area_shp.rda")) %>%
  #convert from 4269 
  st_transform(crs_deg)

```

```{r}
# common variables
original_var_labels <- unique(mm_predictions$var0)

cov_names <- select(mm_cov, m_to_a1:last_col()) %>% names()


```


# Correlations

```{r}

cor_df <- mm_predictions %>%
  mutate(
  pollutant = if_else(grepl("UFP", variable),
                      paste0(variable, "\n", ufp_range_nm),
                      as.character(variable)
  )
  ) %>%    
  select(pollutant, location, prediction) %>%   
  spread(pollutant, prediction) %>%  
  select(contains(c("UFP", "BC", "NO2", "PM2.5", "CO2")))

```

```{r}

#function colors upper panel by correlation value
# source: https://stackoverflow.com/questions/45873483/ggpairs-plot-with-heatmap-of-correlation-values 

color_cor <- function(data, mapping, method="p", use="pairwise", alpha=0.5, ...){
  #GGally, #ggpairs()
  pacman::p_load(GGally)
  
  # grab data
  x <- eval_data_col(data, mapping$x)
  y <- eval_data_col(data, mapping$y)
  
  # calculate correlation
  corr <- cor(x, y, method=method, use=use)
  
  # calculate colour based on correlation value
  # Here I have set a correlation of minus one to blue, 
  # zero to white, and one to red 
  # Change this to suit: possibly extend to add as an argument of `my_fn`
  colFn <- colorRampPalette(c("blue", "white", "red"), interpolate ='spline')
  fill <- colFn(100)[findInterval(corr, seq(-1, 1, length=100))]
  
  ggally_cor(data = data, mapping = mapping, 
             #don't include stars if correlations "sign"
             stars = FALSE,
             digits=2,
             ...) + 
    theme_void() +
    theme(panel.background = element_rect(fill=alpha(fill, alpha)))
}
 
```

plot 

```{r}
print("Annual average pollutant prediction correlations")

# correlation plot
ggpairs(cor_df, 
        upper = list(continuous = color_cor),
        lower = list(continuous = wrap("smooth_loess", alpha=0.2)),
) + #scale_x_continuous(labels = scales::scientific) 
  scale_x_continuous(guide = guide_axis(check.overlap = TRUE))

ggsave(file.path(image_path, "prediction_correlations.png"), height = 11, width = 11)

 
```



```{r, eval=F}
#table 

#range of correlations 

cor(cor_df, method="p", use="pairwise") %>%
  as.data.frame() %>%
  mutate_all(~.^2) %>%
  kable(caption = "Interpollutant regression-based R2 values", digits = 2) %>%
  kable_styling()

```

# PLS Model Specifics 

```{r}
 
# function labels covariates 

split_cov_name <- function(dt, cov) {
  dt <- suppressWarnings(dt %>%
                           rename(cov_full_name = cov) %>%
                           mutate(
                             Buffer = substr(cov_full_name, nchar(cov_full_name)-4, nchar(cov_full_name)),
                             #for non-buffered covariates, use "0"
                             Buffer = as.numeric(ifelse(!is.na(as.integer(Buffer)), Buffer, 0)),
                             #drop buffer repetition
                             cov = ifelse(Buffer==0, cov_full_name, substr(cov_full_name, 1, nchar(cov_full_name)-5) )
                           )
  ) %>%
    select(contains("cov"), Buffer, everything())
  
  # elevation
  dt$cov[grepl("^elev_.+_above$", dt$cov_full_name)] <- "elev_above"
  dt$cov[grepl("^elev_.+_below$", dt$cov_full_name)] <- "elev_below"
  dt$cov[grepl("^elev_.+_stdev$", dt$cov_full_name)] <- "elev_stdev"
  dt$cov[grepl("^elev_.+_at_elev$", dt$cov_full_name)] <- "elev_at_elev"
  
  dt$Buffer[grepl("_1k_", dt$cov_full_name)] <- 1000
  dt$Buffer[grepl("_5k_", dt$cov_full_name)] <- 5000
  
  return(dt)
}

```

```{r}

# variance explained
lapply(train_validation_models, function(x) {
  pls_model = x$pls_model
  total_variance_expl = sum(explvar(pls_model)) %>% round()
  print(paste0("variance explained: ", x$variable, ": ", total_variance_expl, "%"))
  
})

```

```{r}
all_pls_loadings <- lapply(train_validation_models, function(x) {
  #x = train_validation_models[1]
  pls_model = x$pls_model
  
  pls_loadings0 = pls_model$loadings[,1:pls_comp_n] %>% as.data.frame() %>%
    rownames_to_column(var="cov")
  names(pls_loadings0) <- make.names(names(pls_loadings0))
  
  pls_loadings <- pls_loadings0 %>%
    split_cov_name() %>%
    #make long format for faceting
    gather(key = "Component", value = "Loading", contains("Comp")) %>%
    mutate(Component = as.numeric(substr(Component, nchar(Component), nchar(Component))),
           variable = x$variable
           )
  
  return(pls_loadings)
  
  }) %>%
  bind_rows()  %>%
  variable_relabel() 

```

covariates with largest loadings

```{r}
# table
all_pls_loadings %>%
  filter(Component ==1) %>%
  group_by(variable, ufp_range_nm) %>% 
  arrange(desc(abs(Loading))) %>%  
  slice(1:30) %>% 
  distinct(cov, variable, ufp_range_nm) %>%
  kable(caption = "covariates in Comp.1 with largest loadings") %>%
  kable_styling()




# PLOT
print("PLS component loadings")

all_pls_loadings  %>%
  #only show P-TRAK results
  filter(!(grepl("UFP", variable) & ufp_range_nm != "10-700 nm")) %>%  
  mutate(
    variable = factor(variable, levels = pollutant_levels2)
  ) %>%
  ggplot(aes(x = Loading, y = cov)) +
  geom_vline(xintercept=0, linetype=2, alpha=0.5) +
  geom_point(aes(size=Buffer, col=variable), shape=1, alpha=0.7) +
  facet_grid(~Component, labeller = "label_both") +
  labs(y = "Geocovariate",
       size = "Buffer (m)",
       col = "Pollutant"#,
       ) +
  theme(legend.position = "right") 

ggsave(file.path(image_path, "pls_loadings.png"), width = 8, height = 11)


```


# Prediction 

## Scatterplots: estimates vs predictions

```{r, fig.height = 12}
mm_predictions %>%
  variable_relabel(var = "var0") %>% 
  ggplot(aes(x=value, y=prediction)) +
  facet_wrap_equal(~variable+ufp_range_nm, scales="free") + 
  geom_abline(slope = c(1, 0.75, 1.25), intercept = 0, alpha=0.2, linetype=2) +
  geom_label(aes(x=Inf, y=Inf, label = "1-1"), vjust = "inward", hjust = "inward") +
  geom_point(alpha=0.3) + 
  geom_smooth(method = "lm") +
  theme(aspect.ratio = 1) + 
  labs(x = "Estimate", y= "Prediction")
  
ggsave(file.path(image_path, "scatter_plot.png"), width = 8, height = 8)

```

## maps

```{r}
#need bbox w/ lat/long coordinates
bbox <- st_bbox(st_transform(st_buffer(st_transform(monitoring_area_shp, crs_m), 10000), crs_deg))

names(bbox) <- c("left", "bottom", "right", "top")

map0 <- suppressMessages(get_stamenmap(
  bbox = bbox, 
  zoom = 11, 
  maptype = "toner-lite" #has airport symbol
  #maptype = "toner-background" #roads & water but no airport
))

## map labels
map_x_labels <- c(seq(-122.5, -121.9, 0.2)) #0.2
map_y_labels <- c(seq(47.2, 48, 0.2)) #%>% format(nsmall=1)



grid_predictions2 <- st_as_sf(grid_predictions, coords = c("longitude", "latitude"),  remove = F, crs=crs_deg) %>%
  variable_relabel() 

unique_pollutants <- unique(grid_predictions2$variable) %>% sort()

non_ufp_p <- str_subset(string =  unique_pollutants, pattern = "UFP", negate = T) %>%
  sort()

ufp_p <- str_subset(string =  unique_pollutants, pattern = "UFP", negate = F) %>%
  sort()


```

# Prediction Errors

### maps - where are the large errors

```{r, fig.height = 12}

#non-ufp
lapply(non_ufp_p, function(i) {
  #i== non_ufp_p[1]
  ggmap(ggmap = map0, darken = c(.5, "white")) +
      geom_point(data=filter(mm_predictions, variable == i), aes(x=longitude, y=latitude, col=residual)) + 
      facet_wrap(~variable) + 
      scale_color_gradient2(name = "Conc", low = "blue", high = "red", ) + 
    labs(title = "model residuals (prediction - estimate)")
  }) %>%
  ggarrange(plotlist = .)

# ufp
lapply(ufp_p, function(i) {
  ggmap(ggmap = map0, darken = c(.5, "white")) +
      geom_point(data=filter(mm_predictions, variable == i), aes(x=longitude, y=latitude, col=residual)) + 
      facet_wrap(~variable+ufp_range_nm) + 
      scale_color_gradient2(name = "Conc", low = "blue", high = "red") +
    labs(title = "model residuals (prediction - estimate)")
  }) %>%
  ggarrange(plotlist = .)

```

### Lasso - Error predictors

```{r}
# fn runs lasso and returns a list: a) covariate estimates: b) lambda

lasso_fn <- function(dt, x_names, y_name, family. = "gaussian", lambda. = "") {
  
  pacman::p_load(glmnet)
  
  x <- model.matrix(as.formula(paste(y_name, "~", 
                                     paste(x_names, collapse = " + "))
  ), dt)[, -1]
  
  #replace y "name" w/ actual data
  y <- dt[[y_name]]   
  
  #select lambda through CV if not supplied
  if(lambda. == ""){
    cv.out <- cv.glmnet(x = x,
                        y = y, 
                        alpha=1, 
                        family= family., 
                        standardize=T)
    
    lambda. <- cv.out$lambda.min
  }
  
  # run Lasso
  lasso.m <- glmnet(x = x,
                    y = y, 
                    alpha = 1, 
                    family= family.,  
                    standardize = T)
  
  #save coefficient estimates
  lasso_coef <- predict(lasso.m, 
                        type= "coefficients",  
                        s= lambda.)[1:(ncol(x)+1),] %>%
    as.data.frame() %>%
    rownames_to_column() %>%
    rename(cov = rowname,
           coef = ".") %>%
    #keep coefficients that are not 0 or intercept values
    filter(coef != 0,
           cov != "(Intercept)")
  
  
  results <- list(results = lasso_coef,
                  lambda = lambda.
  )
  
  return(results)
  
}
```

```{r}

lasso_results <- lapply(original_var_labels, function(x) {
  # x=original_var_labels[2]
  lm <- filter(mm_predictions, var0==x) %>%
    left_join(mm_cov[,c("location", cov_names)]) %>% #View() 
    lasso_fn(dt = ., x_names = cov_names,  y_name = "residual")
  
  result <- lm$results %>%
    mutate(variable = x)
  }) %>%
  bind_rows()

```



```{r, fig.height = 12}
lasso_results %>%
   variable_relabel() %>%  
  ggplot(aes(x=coef, y=cov, col=ufp_range_nm)) + 
  facet_wrap(~variable, scales = "free") +
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  geom_point() + 
  labs(col = "UFP Range\n(nm)")
  
```

Land use features

* where are the places that stand out?

 
```{r, fig.height=12}
#show were variables that stand out are
vars <-c("bus_s01000", 
         #ufp
         "lu_mix_barren_p10000", "lu_mine_p00050",
         #bc
         "rlu_crop_p00400", "lu_shrub_p00750",
         #no2
         "lu_wetland_p10000", 
         #co2
         "lu_nf_wetland_p15000")

lapply(vars, function(x) {
  # x = vars[1]
  ggplot(grid_cov, aes(x=longitude, y=latitude, col=!!as.symbol(x))) +
    geom_point() +
    geom_sf(data=monitoring_area_shp, inherit.aes = F, show.legend = F,
            aes(fill = "Monitoring Area"), alpha=0, lwd = 1) +
    theme(legend.position = "bottom")
  }) %>%
  ggarrange(plotlist = .)

 
  
  
```



# Grid Prediction Maps 


```{r, fig.height = 12}
 
#non-UFPs. each pollutant has its own legend

print("Annual average pollutant concentrations at monitoring sites (N=309).")

p <- list() 

for(i in seq_along(non_ufp_p)) {
  #i=1
  
  p[[i]] <- ggmap(ggmap = map0, darken = c(.5, "white")) +
    # #monitoring area
    # geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"), alpha=0.1, lwd = 0.1) +
    
    #annual averages
    geom_sf(data=filter(grid_predictions2, variable %in% non_ufp_p[i]), 
            aes(col=prediction), inherit.aes = F, size=2.5
            )  +
    
    scale_color_gradient(name = "Conc", low = "yellow", high = "red") +
    facet_wrap(~variable)  + 
    # add scale & N arrow to top rught
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +
    
    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
    ) +
    theme_bw() +
    theme(
      legend.justification=c(0,1),  
      legend.position=c(0,1),  
      legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels,
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                       )
    ) +
    #arrange legend order
    # guides(col = guide_colorbar(order = 2),
    #        fill = guide_legend(order = 1)
    # ) +
    #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                  label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
    ),
    size=2.5
    ) +
    labs(x = "Longitude",
         y = "Latitude"#, fill = ""
    ) 
  
  p[[i]]
  
}

ggarrange(plotlist = p, ncol = 2, nrow = 2)

ggsave(file.path(image_path, "prediction_map_non_ufp.png"),  height = 13, width = 11)

```

```{r, fig.height = 12}

# UFP's. have same legend.

ggmap(ggmap = map0, darken = c(.5, "white")) +
  # #monitoring area
  # geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"), alpha=0.1, lwd = 0.1) +
  # 
  #annual averages
  geom_sf(data=filter(grid_predictions2, variable %in% ufp_p), aes(col=prediction), inherit.aes = F, size=2.5)  +
  scale_color_gradient(name = "Conc", low = "yellow", high = "red") +
  facet_wrap(~variable+ufp_range_nm, #Instrument~ufp_range_nm,
             nrow = 2)  + 
  # add scale & N arrow to top rught
  annotation_scale(location = "tr") +
  annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +
  
  annotation_north_arrow(location = "tr",
                         #point towards North Pole
                         which_north = "true",
                         pad_y = unit(0.5, "in"),
                         style = north_arrow_fancy_orienteering
  ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank(),
  ) +
  coord_sf(expand = F) +
  scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
  scale_y_continuous(breaks = map_y_labels, 
                     labels = format(map_y_labels,digits = 1, nsmall = 1)
  ) +
  # #arrange legend order
  # guides(col = guide_colorbar(order = 2),
  #        fill = guide_legend(order = 1)) +
  #add attribution/reference to bottom left
  geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
  ),
  size=2.5
  ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
  ) 

ggsave(file.path(image_path, "prediction_map_ufp.png"),  height = 13, width = 11)


```



 