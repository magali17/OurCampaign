---
title: "Campaign Data Summary"
author: "Magali Blanco"
date: ' `r Sys.time()` '
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    number_sections: true
    toc_float: true
    collapsed: false
    smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

```{r, echo=F}
##merge with github. always do these 4 steps all together. enter the following into the Terminal.
# 
###a. git pull origin master #do this before start editing & before you're read to upload changes again
###b. git add _____.Rmd 
###c. git commit -m "___my commit message in parentheses" 
###d. git push origin master
# 
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=F, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 6, fig.width = 10
                      )  

# # Clear workspace of all objects and unload all extra (non-base) packages
# rm(list = ls(all = TRUE))
# if (!is.null(sessionInfo()$otherPkgs)) {
#   res <- suppressWarnings(
#     lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
#       detach, character.only=TRUE, unload=TRUE, force=TRUE))
# }

pacman::p_load(knitr, kableExtra, broom,
               ggpubr, tidyverse,
               ggrepel, #geom_label_repel
               ggmap, sf, ggspatial, #mapping...adding scales, N arrows
               ggrepel, #avoid overlapping labels
               units, #convert between e.g., m to km
               #time series data 
               lubridate,
               
               fmsb, #percentile()
               GGally, #ggpairs()
               VCA, #anovaVCA()
               gstat, #variogram()
               ggpmisc, # for ggplot() geom="table"
               units, #convert between e.g., m to km
               colorspace #create color palates that "look good". e.g., rainbow_hcl(3)
               )    
 

set.seed(1)

theme_set(theme_bw())
theme_update(legend.position = "bottom")

image_path <- file.path("..", "Manuscript", "Images")

```


# Upload data

###--> add uncalibrated data/other data for sensitivity analyses 

```{r}
#functions
source("0_Functions.R")

# 'locations' table
load(file.path("Data", "Original", "locations_table.rda"))

#definitions: ap 
load(file.path("Data", "Output", "common_vars.rda"))

#stop data
sec0 <- readRDS(file.path("Data", "Output", "second_data.rda"))
stops0 <- readRDS(file.path("Data", "Output", "stop_data.rda"))
ns0 <-readRDS(file.path("Data", "Output", "ns_stop_data.rda"))
trh0 <-readRDS(file.path("Data", "Output", "trh_stop_data.rda"))


#geocovariates
geo <- readRDS(file.path("~", "Documents","School","PhD", "Dissertation", "TRAP R Project","Data", "Aim 2", "Geocovariates", "cov_mm_preprocessed.rda"))

```

 
```{r}
#mapping
crs_m <- 32148
crs_deg <- 4326 #WGS84. in decimal degrees

#shapefiles
monitoring_area_shp <- readRDS(file.path("Data", "Output", "GIS", "monitoring_area_shp2.rda")) %>%
  #convert from 4269 
  st_transform(crs_deg)

```

```{r}
gis_path0 <- file.path("~", "Documents", "School", "PhD", "Dissertation", "GIS", "Shapefiles")
# project_crs <- 4326  #lat/long
# m_crs <- 32148 #meters

```

```{r}
 
keep_names <- setdiff(names(stops0), c("instrument_id", "primary_instrument", "ufp_range_nm")) #"value_c1", "value_raw", 

# calculate UFPs 20-36 nm using PTRAK data
ufp_20_36 <- stops0 %>%
  filter(grepl("PMPT", instrument_id)) %>%
  select(keep_names) %>%
  gather("value_v", "value", contains("value")) %>%
  mutate(variable = paste0(variable, "_", value_v)) %>%
  select(-value_v) %>%
  spread(variable, value) %>%
  drop_na() %>%
  mutate(
    pnc_20_36_value = pnc_noscreen_value - pnc_screen_value,
    pnc_20_36_value_c1 = pnc_noscreen_value_c1 - pnc_screen_value_c1,
    pnc_20_36_value_raw = pnc_noscreen_value_raw - pnc_screen_value_raw
  ) %>%
  gather("variable", "value", contains("pnc_")) %>%
  mutate(
    value_v = str_extract(variable, "v.*"),
    variable = sub("_v.*", "", variable )
  ) %>%
  spread(value_v, value) %>%
  filter(grepl("20_36", variable))

# add stop #s
stop_no <- stops0 %>%
  distinct(location) %>% 
  mutate(location_no = row_number()) 

stops0.1 <- stops0 %>%
  select(keep_names) %>%
  #add new UFP estimates
  rbind(ufp_20_36) %>%
  # add stop #
  left_join(stop_no) %>%
  # add other labels/temporal variables
  mutate(
    variable = ifelse(grepl("neph", variable), "pm2.5_ug_m3", variable),
    day = wday(time,label = T, week_start = 1),
    hour = hour(time),
    pollutant = variable,
  ) %>%
  variable_relabel(var = "pollutant") %>%
  mutate(pollutant2 = ifelse(grepl("UFP", pollutant), 
                             paste0(pollutant, ", ", ufp_range_nm),
                             as.character(pollutant)
                             )
         ) %>%
  add_season(.date_var = "date") 
  
```

```{r}

# add labels to ns data
ns <- ns0 %>%
  #don't look at this for now?
  filter(!variable %in% c("mode")) %>%
  
  # add stop #
  left_join(stop_no) %>%
  mutate(
    ufp_range_nm = case_when(
      variable == "11.5" ~ "10.0-13.3",
      variable == "15.4" ~ "13.3-17.8",
      variable == "20.5" ~ "17.8-23.7",
      variable == "27.4" ~ "23.7-31.6",
      variable == "36.5" ~ "31.6-42.2",
      variable == "48.7" ~ "42.2-56.2",
      variable == "64.9" ~ "56.2-75.0",
      variable == "86.6" ~ "75.0-100.0",
      variable == "115.5" ~ "100.0-133.4",
      variable == "154.0" ~ "133.4-177.8",
      variable == "205.4" ~ "177.8-237.1",
      variable == "273.8" ~ "237.1-316.2",
      variable == "365.2" ~ "316.2-421.7",
      variable == "median" ~ "median"#,
      #variable == "mode" ~ "mode",
      )
  ) %>%
  # add other labels/temporal variables
  mutate(
    day = wday(time,label = T, week_start = 1),
    hour = hour(time),
    
  ) %>%
  add_season(.date_var = "date") %>%
  mutate(pollutant = "UFP (pt/cm3)",
         pollutant2 = paste0(pollutant, ", ", ufp_range_nm)
         ) 

#common variable
bin_var_lvs <- ns %>%
  distinct(variable, ufp_range_nm) %>%
  arrange(variable) %>%
  pull(variable) %>%
  as.character() %>%
  c(., "pnc_20_36", "pnc_screen")
  
bin_range_lvs <- ns %>%
  distinct(variable, ufp_range_nm) %>%
  arrange(variable) %>%
  pull(ufp_range_nm) %>%
  c(., "20-36", "36-1,000")

ptrak_bin_range <- c("20-36", "36-1,000")
ns_bin_range <- setdiff(bin_range_lvs, c("median", ptrak_bin_range))


### --> shouldn't this be done already? 
#ns <- ns %>% drop_na(value)

```


```{r}
bin_vars <- intersect(names(stops0.1), names(ns))

stops <- stops0.1 %>%
  #don't include calcualted PTRAK bin
  filter(!variable %in% c("pnc_20_36"#, "pnc_screen"
                          )) 
  
stops_bins <- stops0.1 %>%
  #don't include PTRAK bins here
  filter(variable %in% c("pnc_20_36", "pnc_screen")) %>%
  select(bin_vars) %>%
  rbind(select(ns, bin_vars)) %>%
  mutate(
    instrument = ifelse(grepl("pnc_", variable), "P-TRAK", "NanoScan"),
    #organize bins
    variable = factor(variable, levels = bin_var_lvs),
    ufp_range_nm = factor(ufp_range_nm, levels = bin_range_lvs)
  )

```


instrument names

```{r}
instruments <- stops %>%
  distinct(variable, pollutant, pollutant2) %>%
  mutate(
    Instrument = c("MA200", "SenseAir", "M903", "DiSCmini", "P-TRAK, Screen", "NanoScan", "CAPS", "P-TRAK")
  )

```



common variables

```{r}
low_boxplot_q <- 0.05
high_boxplot_q <- 0.95

# maps
## map labels
map_x_labels <- c(seq(-122.5, -121.9, 0.2)) #0.2
map_y_labels <- c(seq(47.2, 48, 0.2)) #%>% format(nsmall=1)
 
unique_pollutants <- unique(stops$pollutant) %>% sort()
unique_pollutants2 <- unique(stops$pollutant2) %>% sort()
uniqe_variables <-  
  relevel( 
  factor(unique(stops$variable)), 
                           ref = "no2" )

bin_instruments <- sort(unique(stops_bins$instrument))

```

# Route Statistics


```{r}
# annie's work 
on_road <- readRDS(file.path("Data", "Annie", "route_stats_08.02.21.rds"))

```



```{r}
# route distance
 
routes_shp <- read_sf(file.path(gis_path0, "Routes 190910", "All routes.shp")) %>%
  st_transform(crs_deg) %>%
  mutate(
    Route = as.factor(Route)
  )

```

```{r}
#function returns number with exact number of digits desired. e.g., adds trailing 0s if needed.

specify_decimal <- function(x, k) {
  result <- trimws(format(round(x, k), nsmall=k)) %>%
    as.numeric()
  
  return(result)
}


```


```{r}
  #group_by(Route) %>%
#st_union(by_feature = T)
  #st_combine()

route_dist <- routes_shp %>%
  #calculate length of each piece of route string
  mutate(length_mi = as.numeric(set_units(st_length(.), "mi")),
         length_km = as.numeric(set_units(st_length(.), "km")),
         ) %>%
  st_drop_geometry() %>% as.data.frame() %>%
  #total route distnace
  group_by(Route) %>%
  summarise(length_mi = sum(length_mi),
            length_km = sum(length_km),
            )  
  

```



```{r}

#basic route stats
route_stats <- stops %>%
  mutate(
    Route = substr(runname, 14, nchar(runname))
  ) %>%
  group_by(Route) %>%
  summarize(
    stops = length(unique(location)),
    dates = length(unique(runname))
  ) %>%
  left_join(route_dist) %>%
  mutate(
    total_distance_mi = dates * length_mi,
    total_distance_km = dates * length_km
  ) 

#total row
tot <- route_stats %>%
  summarize(
    Route = "Total",
    stops = sum(stops),
    dates = max(dates),
    length_mi = sum(length_mi),
    length_km = sum(length_km),
    total_distance_mi = sum(total_distance_mi),
    total_distance_km = sum(total_distance_km)
    )

# combine
route_stats1 <- route_stats %>%
  rbind(tot) %>%
  left_join(on_road) 

route_stats1 %>%
  kable(caption = "Route statistics. Number of sampling dates includes makeup routes, which may have been slightly altered.", 
        col.names = c("Route", "No. Stops", "No. Sampling Dates", "Distance (mi)","Distance (km)", "Total Distance (mi)", "Total Distance (km)", "No. Road Segments", "Median (IQR) Drive Time (hr)", "Total Drive Time (hr)" #names(on_road)[-1]
                      ),
        digits = 0, 
        format.args = list(big.mark = ",")
        ) %>%
  kable_styling()  


```


range estimates

```{r}
route_stats1 %>%
  slice(-10) %>%
  mutate_if(is.numeric, ~round(., 0)) %>%
  summarize(
    stops = paste0(min(stops), " - ", max(stops)),
    dates = paste0(min(dates), " - ", max(dates)),
    length_km = paste0(min(length_km), " - ", max(length_km)),
    length_mi = paste0(min(length_mi), " - ", max(length_mi)),
    total_distance_km = paste0(min(total_distance_km), " - ", max(total_distance_km)),
    total_distance_mi = paste0(min(total_distance_mi), " - ", max(total_distance_mi)),
    
  ) %>%
  kable(caption = "route-specific statistic ranges") %>%
  kable_styling()


```



# Drive Days

```{r}
#total 
stops %>%
  distinct(runname) %>%  
  summarize(total_drive_days = n()) %>%
  kable(caption = "total drive days") %>%
  kable_styling()

## by instrument
stops %>%
  group_by(pollutant, ufp_range_nm) %>%
  distinct(runname) %>%  
  summarize(total_drive_days = n()) %>%
  kable(caption = "total drive days, by instrument") %>%
  kable_styling()

```

```{r}
stops %>%
  mutate(hour = ifelse(hour==0, 24, hour)) %>% 
  summarize(
    Earliest_sampling_hour = min(hour),
    Latest_sampling_hour = max(hour)
  ) %>%
  kable(caption = "earliest and latest sampling hour in campaign") %>%
  kable_styling()

```


# Stop medians

## Sample size

* this is for the stops the mobile platform completed. some instruments may have fewer readings (e.g., due to instrument issues)

```{r}
stops %>%
  distinct(runname, location) %>%  
  #visits per location
  group_by(location) %>%
  summarize(
    N_visits = n()
  ) %>%   
  #disgtribution of number of site visits
  summarize(
    N = n(),
    Min = min(N_visits),
    Q25 = quantile(N_visits, 0.25),
    Mean = mean(N_visits),
    SD = sd(N_visits),
    Median = quantile(N_visits, 0.50),
    IQR = IQR(N_visits),
    Q75 = quantile(N_visits, 0.95),
    Max = max(N_visits),
  ) %>%
  kable(caption = "number of visits to each location", 
        digits = 1
        ) %>%
  kable_styling() 
  
```

number of visits at different times of the day    
* showing example for UFPs since all pollutant trend were similar    
* sites were visited every season and day of the week    
* sites were more likely to be visited during certain hours: early morning, early afternoon, and evening hours


```{r}

print("total number of site visits")

stops %>%
  #show UFPs as an example
  filter(variable == "pnc_noscreen") %>%

  gather(temporal_var, temporal_value, season, day, hour) %>%
  mutate(
    temporal_var = factor(temporal_var, levels = c("season", "day", "hour")),
    temporal_value = factor(temporal_value, 
                            levels = c(levels(stops$season), levels(stops$day), c(0:23) )
                              )
    ) %>%  
  # group_by(temporal_var, temporal_value, location, location_no, variable) %>%
  # summarize(count = n()) %>%
  
  ungroup() %>%
  mutate(location_no = factor(location_no)) %>%
  
  ggplot(aes(x=temporal_value,
             y=location_no,
             #group=location_no
             )) + 
  facet_grid(pollutant~temporal_var, scales="free") + 
  geom_bin2d(
    #binwidth = c(1, 1),
    #bins=length(unique(stops$location_no))
             ) +
  #scale_y_discrete(breaks = seq(10, 309, 10)) +
  scale_y_discrete(guide = guide_axis(check.overlap = T))+
  
  #scale_x_discrete(guide = guide_axis(check.overlap = T))+
  labs(
       x = "Sampling Time" ,
       y="Site",
       fill = "No. Visits"
       )

ggsave(file = file.path(image_path, "SI", "samples_per_site.png"),
         height = 9, width = 10)

```



## Concentration Table

```{r}

location_quant <- stops %>%
  #calc stats for alternative boxplots
  group_by(pollutant, ufp_range_nm, location, location_no) %>%
  alt_boxplot(var = "value", min_q = low_boxplot_q, max_q = high_boxplot_q) %>%
  mutate(iqr = Q75-Q25,
         qmax_qmin = Qmax/Qmin,
         max_min = Max/Min
         )

location_quant_bins <- stops_bins %>%
  #calc stats for alternative boxplots
  group_by(pollutant, ufp_range_nm, instrument, variable, location, location_no) %>%
  alt_boxplot(var = "value", min_q = low_boxplot_q, max_q = high_boxplot_q) %>%
  mutate(iqr = Q75-Q25,
         qmax_qmin = Qmax/Qmin,
         max_min = Max/Min,
         
         #organize bins
         variable = factor(variable, levels = bin_var_lvs),
    ufp_range_nm = factor(ufp_range_nm, levels = bin_range_lvs)
         )





#levels(location_quant_bins$ufp_range_nm)


```



```{r}
# conc table

stops %>%
  left_join(instruments) %>%
  mutate(
    pollutant = as.character(pollutant),
    pollutant = ifelse(grepl("UFP", pollutant), paste0(pollutant, ", ", ufp_range_nm), pollutant)
         ) %>%
  group_by(Pollutant=pollutant, Instrument) %>%
  summarize(
    N = n(),
    #Min = min(value),
    Q05 = quantile(value, 0.05),
    Q25 = quantile(value, 0.25),
    Median = quantile(value, 0.50),
    Q75 = quantile(value, 0.75),
    Q95 = quantile(value, 0.95)
    #Max = max(value),
    #IQR = IQR(value)
    ) %>%
  mutate(
  'Q95/Q05' = format(Q95/Q05, digits = 2),
  ) %>%
  
  mutate(Pollutant = gsub(", ", "\n", Pollutant)) %>%
  mutate_at(
    vars(N:Q95), ~ifelse(grepl("UFP|CO2|BC", Pollutant), 
                           format(., digits=0, scientific = F, big.mark = ","),
                           format(., digits=2, scientific = F, big.mark = ",")
                           )
  ) %>%
  kable(caption = ". Distribution of site visit pollutant concentrations (N = 309 sites x ~ 29 visits/site).") %>%
  kable_styling()

```


## Site Variability

* boxplots of site visit medians.    
* whiskers are for the quantiles: `r low_boxplot_q` and `r high_boxplot_q`

```{r}
# load between site variabiltiy (later)

annual_conc1 <- readRDS(file.path("Data", "Output", "annual_conc_table.rda")) %>%
  mutate(
    IQR = Q75-Q25
  ) %>%
  select(Pollutant, Instrument, IQR) %>%
  mutate(
    IQR = ifelse(grepl("UFP|CO|BC|NO2", Pollutant), 
                           format(IQR, digits=0, scientific = F, big.mark = ",", 
                                  ),
                           format(IQR, digits=1, scientific = F, big.mark = ",", 
                                  )
                  )
    )


```


```{r}

# IQR table
location_quant %>%
  mutate(
    pollutant = as.character(pollutant),
    pollutant = ifelse(grepl("UFP", pollutant), paste0(pollutant, ", ", ufp_range_nm), pollutant)
         ) %>%
  #left_join(instruments, by=c("pollutant" = "pollutant2")) %>%
  group_by(Pollutant=pollutant, #Instrument
           ) %>%
  summarize(
    Min = min(iqr),
    Median = quantile(iqr, 0.50),
    Max = max(iqr),
    ) %>%
  mutate(
    'Max/Min' = format(Max/Min, digits = 2),
  ) %>%
  mutate_at(
    vars(Min:Max), ~ifelse(grepl("UFP|CO2|BC", Pollutant), 
                           format(., digits=0, scientific = F, big.mark = ",",  
                                  justify = "left"
                                  ),
                           format(., digits=2, scientific = F, big.mark = ",", 
                                  justify = "left"
                                  )
                           )
  ) %>% 
  
  mutate(
    Min = gsub(" ", "", Min),    
    Max = gsub(" ", "", Max),
    Median = paste0(Median, " (", Min, "-", Max, ")")
        ) %>%
  select(
    -c(Min, Max)
  ) %>%
  
  left_join(annual_conc1) %>%
  relocate(Instrument, .after=Pollutant) %>%
  
  kable(caption = 
          "Comparison of within and between site variability. Within site variability is for site-specific IQR values of median visit concentrations (N = 309 site IQRs, each site has approximately 29 visits) and thus shows visit concentration data. Between site variability  is for the IQR of annual average concentrations (N=309 sites), as shown in Table ___.",
        
          #"Distribution of site-specific IQR values for median visit concentrations (N = 309 site IQRs, each site has approximately 29 visits).", 
        col.names = c("",  "",
                      "Median (Range) IQR", 
                      "Max/Min IQR", 
                      "IQR"), 
        align = "r",   
        #format.args = list(big.mark = ",")
        ) %>%
  kable_styling() %>%
  add_header_above(c("Pollutant", "Instrument", "Within-Site Variability of Median Visit Conc's" = 2, "Between-Site Variability of Annual Avg Conc's" = 1))

```

 


boxplots

```{r}

# like table above, but formatted differently
visit_conc <- stops %>%
  group_by(pollutant, ufp_range_nm) %>%
  summarize(
    Q05 = quantile(value, 0.05),
    Median = quantile(value, 0.50),
    Q95 = quantile(value, 0.95),
    )  
## for bins
visit_conc_bins <- stops_bins %>%
  group_by(pollutant, ufp_range_nm, variable, instrument) %>%
  summarize(
    Q05 = quantile(value, 0.05),
    Median = quantile(value, 0.50),
    Q95 = quantile(value, 0.95),
    )  %>%
  arrange(instrument) %>%
  mutate(
    #organize bins
         variable = factor(variable, levels = bin_var_lvs),
    ufp_range_nm = factor(ufp_range_nm, levels = bin_range_lvs)
  )

```

 
```{r}
line_col <- "red"
line_a <- 0.5

print("Distribution of visit concentrations by site for PM2.5, BC, NO2 and CO2 (N~29 visits per site). Boxes show the site-specific 25th, 50th and 75th quantile; whiskers show the 5th and 95th quantiles. Vertical lines show the median (solid), 5th (dashed), and 95th (dashed) quantile concentration for all the sites.")

#non-ufp plots
location_quant %>%
  filter(!grepl("UFP", pollutant)) %>%

  ggplot(aes(y=factor(location_no), #col=ufp_range_nm
             )) +
  geom_boxplot(aes(xmin=Qmin, xlower=Q25, xmiddle=Q50, xupper=Q75, xmax=Qmax), stat = "identity", 
               #alpha=0.2
               ) +
  # show overall pollutant quantiles: 5, 50, 95 
  geom_vline(data=filter(visit_conc, !grepl("UFP", pollutant)), aes(xintercept = Median), alpha=line_a, linetype=1, col=line_col) +
  geom_vline(data=filter(visit_conc, !grepl("UFP", pollutant)), aes(xintercept = Q05), alpha=line_a, linetype=2, col=line_col) +
    geom_vline(data=filter(visit_conc, !grepl("UFP", pollutant)), aes(xintercept = Q95), alpha=line_a, linetype=2, col=line_col) +
  
  facet_wrap(~pollutant+ufp_range_nm, scales="free_x", nrow = 1) +
  scale_y_discrete(breaks = seq(10,310, 10)) +
  labs(y= "Site No.",
         x= "Value")  +
  theme(legend.position = "none") #+ scale_x_log10()
    
ggsave(file = file.path(image_path, "SI", "visit_boxplots_non_ufp.png"),
         height = 9, width = 7)

print("...Note that differnt UFP measures are on different x-axis scales for improved visibility.")

#total ufp plots
location_quant %>%
  filter(grepl("UFP", pollutant),
         #!grepl("36-1,000", ufp_range_nm)
         ) %>%
  ggplot(aes(y=factor(location_no), #col=ufp_range_nm
             )) +
  geom_boxplot(aes(xmin=Qmin, xlower=Q25, xmiddle=Q50, xupper=Q75, xmax=Qmax), stat = "identity") +
  geom_vline(data=filter(visit_conc, grepl("UFP", pollutant)), aes(xintercept = Median), alpha=line_a, linetype=1, col=line_col) +
  geom_vline(data=filter(visit_conc, grepl("UFP", pollutant)), aes(xintercept = Q05), alpha=line_a, linetype=2, col=line_col) +
    geom_vline(data=filter(visit_conc, grepl("UFP", pollutant)), aes(xintercept = Q95), alpha=line_a, linetype=2, col=line_col) +
  
  facet_wrap(~pollutant+ufp_range_nm, scales="free_x", 
             nrow = 1) +
  scale_y_discrete(breaks = seq(10, 310, 10)) +
  theme(legend.position = "none") + 
  labs(y= "Site No.",
         x= "Value") + #geom_vline(xintercept = 20e3, linetype=3, alpha=0.5)
  #theme(axis.text.x = element_text(size = 11))
    scale_x_continuous(guide = guide_axis(check.overlap = TRUE,
                                          #n.dodge=2
                                          ))
  
ggsave(file = file.path(image_path, "SI", "visit_boxplots_ufp.png"),
         height = 9, width = 7)

```



```{r, eval=F}
#- same as above for UFP bins 

#only show lines for one instrument at a time
df <- visit_conc_bins %>%
  filter(instrument == "NanoScan" & !variable %in% c("median", "mode")) 
  
location_quant_bins %>%
  filter((instrument == "NanoScan" & !variable == "median")) %>%
  
  ggplot(aes(y=factor(location_no))) +
  geom_boxplot(aes(xmin=Qmin, xlower=Q25, xmiddle=Q50, xupper=Q75, xmax=Qmax), stat = "identity") +
  geom_vline(data=df, aes(xintercept = Median), alpha=line_a, linetype=1, col=line_col) +
  geom_vline(data=df, aes(xintercept = Q05), alpha=line_a, linetype=2, col=line_col) +
    geom_vline(data=df, aes(xintercept = Q95), alpha=line_a, linetype=2, col=line_col) +
  
  facet_wrap(~instrument+ufp_range_nm,  #+variable
               #scales="free_x", 
             nrow = 1) +
  scale_y_discrete(breaks = seq(10, 310, 10)) +
  theme(legend.position = "none") + 
  labs(y= "Site No.",
         x= "Value") + 
  scale_x_continuous(guide = guide_axis(check.overlap = TRUE,))

  
   
ggsave(file = file.path(image_path, "SI", "visit_boxplots_ns_bins.png"),
         height = 9, width = 12)


```

 

## Temporal Variability 

notes   
* note, plotting non-extreme values, otherwise can't see any trends in the plots    
  - if on log scale, values <=0 are dropped (e.g., many for BC since aethalometer instrument is noisy)   
* note that different sites were visited at different times, so there could be some spatial confounding   
  

* NanoScan (10-420 nm) has higher readings than discmini (10-700 nm) b/c it is more efficient at measuring the smallest particles due to the difference in technologies. The Nanoscan measures optical diameter after alcohol condensation to grow the particles, whereas the disk-mini measures electrical mobility diameter based on the current produced when the particles are captured on a oppositely charged surface.  The electrostatic method has lower detection efficiencies for these very small particles than does the condensation/optical method.

by season 


```{r, fig.height=12}
# by month

print("Median site visit concentrations by season. Lines connect median monthly concentrations.")

stops %>%
    mutate(month =month(time, label = T),
           ) %>%  
    #calc stats for alternative boxplots
    group_by(pollutant, ufp_range_nm, #month, 
             season) %>%
    alt_boxplot(var = "value", min_q = low_boxplot_q, max_q = high_boxplot_q) %>% 
    
    ggplot(aes(x=season, #x=month, 
               fill=ufp_range_nm)) +
    geom_boxplot(aes(ymin=Qmin, lower=Q25, middle=Q50, upper=Q75, ymax=Qmax), stat = "identity") + 
    #stat_summary(aes(y=Q50, group=ufp_range_nm), fun="mean", geom="line", size=1) +
  facet_wrap(~pollutant, #~season
             scales="free", nrow = 3) +
    labs(y= "Value",
         x="Month",
         fill = "UFP Range (nm)"
         )  

ggsave(file = file.path(image_path, "SI", "temporal_season.png"),
         height = 9, width = 7)

```



```{r, eval=F}
#-same as above for bins 

stops_bins %>%
  filter(!variable =="median") %>%
    mutate(month =month(time, label = T)) %>%  
    #calc stats for alternative boxplots
    group_by(instrument, ufp_range_nm, season) %>%
    alt_boxplot(var = "value", min_q = low_boxplot_q, max_q = high_boxplot_q) %>% 
    
    ggplot(aes(x=season, col=ufp_range_nm)) +
    geom_boxplot(aes(ymin=Qmin, lower=Q25, middle=Q50, upper=Q75, ymax=Qmax), stat = "identity") + 
    stat_summary(aes(y=Q50, group=ufp_range_nm), fun="mean", geom="line", size=1) +
  facet_wrap(~instrument, 
             scales="free") +
    labs(y= "Value",
         x="Month",
         col = "UFP Range (nm)"
         )  
```


by weekday

```{r, fig.height=12}
print("Median site visit concentrations by day of the week. Lines connect median monthly concentrations.")

stops %>%
  mutate(dow = ifelse(day %in% c("Sat", "Sun"), "Weekend", "Weekday")) %>%
  #calc stats for alternative boxplots
  group_by(pollutant, ufp_range_nm, #day, 
           dow
           ) %>%
  alt_boxplot(var = "value") %>%  
  
  ggplot(aes(x=dow, #x=day, 
             fill=ufp_range_nm)) +
  geom_boxplot(aes(ymin=Qmin, lower=Q25, middle=Q50, upper=Q75, ymax=Qmax), stat = "identity") + 
  #stat_summary(aes(y=Q50, group=ufp_range_nm,), fun="mean", geom="line", size=1) +
  facet_wrap(~pollutant, scales="free", #space = "free_x"
             nrow = 3) +
  labs(y= "Value",
       x="Day",
       fill = "UFP Range (nm)"
  )


ggsave(file = file.path(image_path, "SI", "temporal_day.png"),
         height = 9, width = 7)                 
```

by hour 

```{r, fig.height=12}

stops %>%
  mutate(hour = factor(hour, levels = c(4:23, 0))) %>%
    #calc stats for alternative boxplots
    group_by(pollutant, ufp_range_nm, hour) %>%
    alt_boxplot(var = "value") %>%  
    
    ggplot(aes(x=hour, fill=ufp_range_nm)) +
    geom_boxplot(aes(ymin=Qmin, lower=Q25, middle=Q50, upper=Q75, ymax=Qmax), stat = "identity") + 
     #stat_summary(aes(y=Q50, group=ufp_range_nm,), fun="mean", geom="line",size=0.3, col="blue") +
    
  facet_wrap(~pollutant+ufp_range_nm, scales="free", nrow = 4
             ) +
    
    labs(y= "Value",
         x= "Hour",
         fill = "UFP Range (nm)"
         )  

ggsave(file = file.path(image_path, "SI", "temporal_hour.png"),
         height = 9, width = 8)                 

```

spaghetti plots
 
```{r}
"Site-specific pollutant concentrations over. Thin lines show site-specific smooth (loess) fits for median visit concentrations (N~29 visits/site). Black lines show the overall smooth trends for all of the sites."

stops %>%
    ggplot(aes(x=time, y=value)) +
   #stat_summary( fun.y=mean, geom="line", size=0.1, alpha=0.3) +
      geom_smooth( se=F,
              size=0.1, alpha=0.8,
              aes(col=ufp_range_nm, group=location), show.legend = F
              ) +
  #overall trend
  geom_smooth(se=F, col="black"
              ) +
  
  facet_wrap(~pollutant+ufp_range_nm, scales="free", nrow = 4) +
    labs(y= "Value",
         x= "Date",
         col = "UFP Range (nm)"
         )  

ggsave(file = file.path(image_path, "SI", "spaghetti_plots.png"),
         height = 9, width = 9)                 

```


 
## ANOVA


```{r}
# using all of the observations to characterize variability 
var_df <- data.frame()


for(i in seq_along(unique_pollutants2)) {
  #i=1
  temp <- anovaVCA(value ~ location + day+ hour + season,
           Data = as.data.frame(subset(stops, pollutant2 == unique_pollutants2[i]) ))$aov.tab  %>% # 
    tidy() %>%
    select(Variable = .rownames, DF, Percent = X.Total) %>%
    mutate(DF = round(DF))
  
  names(temp)[names(temp) == "Percent"] <- as.character(unique_pollutants2[i])
  
  if(i==1) {
    var_df <- temp
    } else {
                                    #only use DF from the first pollutant, as an exp
      var_df <- left_join(var_df, select(temp, -DF))
    }
  }

var_df %>%
  mutate(DF = ifelse(Variable %in% c("total", "error"), "-", DF)) %>%
  select(-DF) %>%
  #rename('Degrees of Freedom' = DF) %>%
  mutate_if(#is.numeric, ~ paste0(round(., 1), "%")
            is.numeric, ~ paste0(format(., digits = 1, nsmall = 1), "%")
            ) %>%
  slice(-1) %>%  
  column_to_rownames(var = "Variable") %>%  
  t() %>% # View()
  
  as.data.frame() %>% rownames_to_column(var = "Pollutant") %>%
  
  #add instrument names 
  left_join(select(instruments, pollutant2, Instrument), by = c("Pollutant" = "pollutant2")) %>%
  relocate(Instrument, .after = Pollutant) %>%
  
  kable(caption = "Percent of variability in visit concentrations explained by spatial and temporal factors (out of 100%). Values are based on separate Analysis of Variance (ANOVA) models for each pollutant. The error term degrees of freedom varies by pollutant.", 
        #digits = 1,  
        col.names = c("Pollutant", "Instrument", "Location (n=309)", "Day of Week (n=7)", "Hour of Day (n=21)", "Season (N=4)", "Residual Error" )
        ) %>%
  kable_styling()

```

* same as above, but modeling all UFP measures/instruments together, and including instrument in the model


```{r, eval=F}

anovaVCA(value ~ location + day+ hour + season + ufp_range_nm,
           Data = as.data.frame(subset(stops, grepl("UFP", pollutant))))$aov.tab  %>% # 
    tidy() %>%
    select(Variable = .rownames, DF, Percent = X.Total) %>%
  mutate(Variable = ifelse(grepl("ufp", Variable), "size range", Variable),
         DF = round(DF)
         ) %>%
  kable(caption = "Percent of UFP visit concentration variability explained by spatial, temporal, and size range (instrument) factors.", 
        digits = 1) %>%
  kable_styling()

```

 


```{r, eval=F}

lm_ufp <- stops %>%
  filter(grepl("UFP", pollutant)) %>%
  mutate(day = as.factor(as.character(day)),
         ) %>%
  lm(value ~ location + day+ hour + season + ufp_range_nm, data = .) 

lm_ufp %>%
  tidy() %>% 
  filter(!grepl("location", term)) %>%
  kable(caption = "LM fit, excluding location terms (modeled as factors). Reference is: Friday, spring, NanoScan") %>%
  kable_styling()
   
  
  
```


# Annual averages

* calculating a simple mean annual average using all the available site data 


## Concentration Table

```{r}
annual <- stops %>%
  left_join(instruments) %>% #View()
  group_by(variable, pollutant, ufp_range_nm, Instrument, location) %>%
  summarize(value = mean(value)) %>%
  ungroup() %>%
  mutate(
    pollutant2 = ifelse(grepl("UFP", pollutant), paste0(pollutant, ", ", ufp_range_nm), as.character(pollutant ))
  ) %>%
  #add location lat/long
  left_join(locations)

annual_bins <- stops_bins %>%
  group_by(variable, pollutant, instrument, ufp_range_nm, location, location_no) %>%
  summarize(value = mean(value)) %>%
  ungroup() %>%
  mutate(
    pollutant2 = ifelse(grepl("UFP", pollutant), paste0(pollutant, ", ", ufp_range_nm), as.character(pollutant ))
  ) %>%
  #add location lat/long
  left_join(locations)
```


```{r}
#table of distribution
annual_conc <- annual %>%
  mutate(
    pollutant = as.character(pollutant),
    pollutant = ifelse(grepl("UFP", pollutant), paste0(pollutant, ", ", ufp_range_nm), pollutant)
         ) %>%
  #left_join(instruments, by = c("pollutant" = "pollutant2")) %>%
  group_by(Pollutant=pollutant, Instrument
           ) %>%
  summarize(
    Min = min(value),
    Q05 = quantile(value, 0.05),
    Q25 = quantile(value, 0.25),
    Median = quantile(value, 0.50),
    Q75 = quantile(value, 0.75),
    Q95 = quantile(value, 0.95),
    Max = max(value),
    ) %>%
  mutate(#'Q95/Q05' = round(Q95/Q05, 1),
         'Max/Min' = round(Max/Min, 1),
         #'IQR/Median' = round((Q75-Q25)/Median, 1)
         ) 

# save for use above. add this between site variability to within site variability table above
saveRDS(annual_conc, file = file.path("Data", "Output", "annual_conc_table.rda"))



annual_conc %>%
  mutate_at(
    vars(Min:Max), ~ifelse(grepl("UFP|CO|BC", Pollutant), 
                           format(., digits=0, scientific = F, big.mark = ","),
                           format(., digits=2, scientific = F, big.mark = ",")
                           #round(.,), 
                           #round(.,1)
                           )
  ) %>%
  
  kable(caption = "Distribution of annual average pollutant concentrations at monitoring sites (N = 309)") %>%
  kable_styling()
  
```

 
```{r}
print("Annual average site concentrations")
  
#boxplots
annual %>%
  ggplot(aes(x=pollutant, y=value, fill=ufp_range_nm)) + 
  facet_wrap(~pollutant, scales= "free") + 
  geom_boxplot() +
  labs(x="Pollutant",
       y = "Value",
       fill = "UFP Range (nm)"
       )

ggsave(file.path(image_path, "SI", "annual_avg.png"), height = 6, width = 7)

```



```{r, eval=F}
#- upf bins

print("Annual average bin-specific UFP site concentrations. N = 309 sites.")

max_val <- max(annual_bins$value)

p <- list()

for(i in seq_along(bin_instruments)) {
  #i=1
p[[i]] <- annual_bins %>%
    filter(variable != "median",
           instrument == bin_instruments[i]
           ) %>%
  ggplot(aes(x=instrument, y=value, col=ufp_range_nm)) + 
  geom_boxplot() +
  ylim(0, max_val) +
  labs(x="Instrument",
       y = "Value",
       col = "UFP\nRange\n(nm)"
       )
  
}

ggarrange(plotlist = p, align = "h")

ggsave(file.path(image_path, "SI", "annual_avg_bin.png"), height = 6, width = 7)

```

```{r, eval=F}

# barplots of site totals 

p <- list()

for(i in seq_along(bin_instruments)) {
  #i=1
  
  p[[i]] <- annual_bins %>%
    filter(variable != "median",
           instrument == bin_instruments[i]
           ) %>%
    ggplot(aes(y=location_no, x=value, fill=ufp_range_nm,)) + 
    geom_bar(stat = "identity", orientation = "y",
             position = position_stack(reverse = TRUE)
             ) + 
    facet_wrap(~instrument) + 
    labs(
      y = "Site No.",
      x = "value",
      fill = "UFP\nRange\n(nm)"
    )
  
  p[[i]]

  }

ggarrange(plotlist = p, ncol=2, align = "h")

ggsave(file.path(image_path, "SI", "site_annual_avg_bin.png"), height = 9, width = 13)

```



-temp, rh annual average for the study area 

```{r}
# site level   
trh0 %>%
  #calculate each site's mean reading
  group_by(location, variable) %>%
  summarize(value = mean(value)) %>%
  #summarize the distribution of site means
  group_by(variable) %>%
  summarize(
    Min = min(value),
    Q05 = quantile(value, 0.05),
    Q25 = quantile(value, 0.25),
    Median = median(value),
    Q75 = quantile(value, 0.75),
    Q95 = quantile(value, 0.95),
    Max = max(value),
  ) %>%
  mutate(
    variable = recode_factor(factor(variable), 
                             "trh_rh" = "Relative Humidity (%)",
                             "trh_temp_f" = "Temperature (F)"
                             )
  ) %>%
  rename(Variable = variable) %>%
  kable(caption = "Distribution of site-specific annual average temperature and relative humidity values. N = 309 sites.", 
        digits = 0
        ) %>%
  kable_styling()

```

note that some sites had slightly more measurements than others, so the average will be slightly skewed towards that location's temp & RH. Hopefully this wno't make a large differnece since the ranges for these measures is narrow? 

```{r}
# overall average 
trh0 %>%
  #calculate each site's mean reading
  group_by(variable) %>%
  summarize(
    N = n(),
    value = mean(value)
    ) %>%
  mutate(
    variable = recode_factor(factor(variable), 
                             "trh_rh" = "Relative Humidity (%)",
                             "trh_temp_f" = "Temperature (F)"
                             ),
    Celcius = ifelse(grepl("Temp", variable), (value-32)*5/9, NA)
  ) %>%
  rename(Variable = variable) %>%
  kable(caption = "Annual average temperature and relative humidity in the study area. N = 309 sites x ~29 visits/site.", 
        digits = 0
        ) %>%
  kable_styling()

```

## Pollutant comparisons

```{r}

cor_df <- annual %>%
  mutate(pollutant = if_else(grepl("UFP", pollutant), 
                            paste0(pollutant, "\n", ufp_range_nm),
                            as.character(pollutant)
                            )
         ) %>%
  select(pollutant, location, value) %>%  
  spread(pollutant, value) %>% 
  select(-location) 
  
```

```{r}
#function colors upper panel by correlation value
# source: https://stackoverflow.com/questions/45873483/ggpairs-plot-with-heatmap-of-correlation-values 

color_cor <- function(data, mapping, method="p", use="pairwise", alpha=0.5, ...){

              # grab data
              x <- eval_data_col(data, mapping$x)
              y <- eval_data_col(data, mapping$y)

              # calculate correlation
              corr <- cor(x, y, method=method, use=use)

              # calculate colour based on correlation value
              # Here I have set a correlation of minus one to blue, 
              # zero to white, and one to red 
              # Change this to suit: possibly extend to add as an argument of `my_fn`
              colFn <- colorRampPalette(c("blue", "white", "red"), interpolate ='spline')
              fill <- colFn(100)[findInterval(corr, seq(-1, 1, length=100))]

              ggally_cor(data = data, mapping = mapping, 
                         #don't include stars if correlations "sign"
                         stars = FALSE,
                         digits=2,
                         ...) + 
                theme_void() +
                theme(panel.background = element_rect(fill=alpha(fill, alpha)))
            }
```


```{r, fig.height=12, fig.width=10}
print("Annual average pollutant correlations")

# correlation plot
ggpairs(cor_df, 
        upper = list(continuous = color_cor),
        lower = list(continuous = wrap("smooth_loess", alpha=0.2)),
        ) + #scale_x_continuous(labels = scales::scientific) 
  scale_x_continuous(guide = guide_axis(check.overlap = TRUE))

ggsave(file.path(image_path, "correlations.png"), height = 11, width = 11)

```

range of correlations 

```{r}
cor(cor_df) %>% as.data.frame() %>%
  summarize(
    Min = min(.),
    Max = max(.[.!=max(.)])
  ) %>%
  kable(caption = "Range of pearson correlations", digits = 2) %>%
  kable_styling()

```



## Maps 

```{r}
# maptype = c("terrain",
#   "terrain-background", "terrain-labels", "terrain-lines", "toner",
#   "toner-2010", "toner-2011", "toner-background", "toner-hybrid",
#   "toner-labels", "toner-lines", "toner-lite", "watercolor")
```

```{r}
 
annual2 <- st_as_sf(annual, coords = c("longitude", "latitude"),  remove = F, crs=crs_deg) #%>% st_transform(crs = crs_m)

#need bbox w/ lat/long coordinates
bbox <- st_bbox(st_transform(st_buffer(st_transform(monitoring_area_shp, crs_m), 10000), crs_deg))

names(bbox) <- c("left", "bottom", "right", "top")

map0 <- suppressMessages(get_stamenmap(
  bbox = bbox, 
  zoom = 11, 
  maptype = "toner-lite" #has airport symbol
  #maptype = "toner-background" #roads & water but no airport
    ))
#map0 %>% ggmap(darken = c(.4, "white"))

  

unique_p <- distinct(annual[c("pollutant", "ufp_range_nm")])

non_ufp_p <- str_subset(string =  unique_p$pollutant, 
           pattern = "UFP", 
           negate = T) %>%
  #factor(levels = levels(annual$pollutant)) %>%
  sort()


ufp_p <- str_subset(string =  unique_p$pollutant, 
           pattern = "UFP", 
           negate = F) %>% unique()



```


```{r, fig.height=18}
#non-UFPs. each pollutant has its own legend

print("Annual average pollutant concentrations at monitoring sites (N=309).")

p <- list() 

for(i in seq_along(non_ufp_p)) {
   #i=1
   
  p[[i]] <- ggmap(ggmap = map0, darken = c(.5, "white")) +
    #monitoring area
    geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"),
            alpha=0.1,
            #reduce/eliminate outline
            lwd = 0.1,
            ) +
    
    #annual averages
    geom_point(data=filter(annual,
                           pollutant == non_ufp_p[i]
                           ),
             aes(x=longitude, y=latitude, col=value), 
             inherit.aes = F, size=2)  +
    scale_color_gradient(name = "Conc",
                        low = "yellow", high = "red",
                        ) +
    facet_wrap(~pollutant)  + 
    # add scale & N arrow to top rught
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       #labels = map_y_labels
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                                       )
                       ) +
    #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 1)
         ) +
    #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
                ),
            size=2.5
            ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
       ) 
  
  p[[i]]
  
  }

ggarrange(plotlist = p, ncol = 2, nrow = 2)

ggsave(file.path(image_path, "map_non_ufp.png"),  height = 13, width = 11)

```

* UFP predictions seem to vary substantially depending on what instrument was used?    
  * note, people wouldn't normally use screened PTRAKS (36-1,000 nm particles) to measure "UFPs"

  
### -->  move PTRAK bins up

```{r}

common_vars <- intersect(names(annual), names(annual_bins))

ptrak_bins <- annual_bins %>%
  filter(instrument == "P-TRAK") %>%
  select(common_vars, "instrument")  
  
ns_few_bins <- annual_bins %>%
  filter(instrument == "NanoScan") %>%
  mutate(
    #ufp_range_nm2 = ifelse(grepl("10.0-13.3   13.3-17.8   17.8-23.7", ufp_range_nm))
    ufp_range_nm2 = case_when(
      ufp_range_nm %in% c("10.0-13.3", "13.3-17.8", "17.8-23.7") ~ "10.0-23.7",
      ufp_range_nm %in% c("23.7-31.6", "31.6-42.2", "42.2-56.2") ~ "23.7-56.2",
      ufp_range_nm %in% c("56.2-75.0", "75.0-100.0") ~ "56.2-100.0",
      ufp_range_nm %in% c("100.0-133.4", "133.4-177.8", "177.8-237.1", "237.1-316.2", "316.2-421.7") ~ "100.0-421.7",
      #TRUE ~ ""
      )
  )


# ptrak <- annual %>%
#   filter(ufp_range_nm == "20-1,000") %>%
#   select(common_vars) %>%
#   rbind(ptrak_bins)


ptrak <- annual %>%
  filter(grepl("pnc_", variable)) %>%
  select(-c(pollutant2, ufp_range_nm)) %>%
  spread(variable, value) %>%
  mutate(pnc_20_36 = pnc_noscreen - pnc_screen) %>%
  gather(variable, value, contains("pnc_")) %>%
  variable_relabel()


```


```{r}
ggmap(ggmap = map0, darken = c(.5, "white")) +
    #monitoring area
    geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"),
            alpha=0.1,
            #reduce/eliminate outline
            lwd = 0.1, 
            show.legend = F
            ) +
    
    #annual averages
    geom_point(data=ptrak,
             aes(x=longitude, y=latitude, col=value), 
             inherit.aes = F, size=2)  +
    scale_color_gradient(name = "Conc",
                        low = "yellow", high = "red",
                        ) +
    facet_wrap(~ufp_range_nm)  + 
    # add scale & N arrow to top rught
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                                       )
                       ) +
    #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 1)
         ) +
  #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
                ),
            size=2.5
            ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
       ) 

ggsave(file.path(image_path, "map_ptrak_tot_and_bins.png"),  
       height = 7, width = 12
       )

```



-all UFP instruments (for SI)
  
  
```{r, fig.height=18}
#UFPs. these share the same legend

ggmap(ggmap = map0, darken = c(.5, "white")) +
    #monitoring area
    geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"),
            alpha=0.1,
            #reduce/eliminate outline
            lwd = 0.1,
            ) +
    
    #annual averages
    geom_point(data=filter(annual, pollutant == ufp_p),
             aes(x=longitude, y=latitude, col=value), 
             inherit.aes = F, size=2,
             )  +
  scale_color_gradient(name = "Conc",
                       low = "yellow", high = "red",
                       ) +
    facet_wrap(Instrument~ufp_range_nm, nrow = 2)  + 
    # add scale & N arrow to top rught
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank(),
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1, nsmall = 1)
                       ) +
  #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 1)) +
  #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
                ),
            size=2.5
            ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
       ) 

ggsave(file.path(image_path, "SI", "map_ufp.png"),  height = 13, width = 11)

```


by UFP bin size


```{r, eval=F}
# - nanoscan # produces too many  maps

p <- list() 

for(i in seq_along(ns_bin_range)) {
   #i=1
   
  p[[i]] <- ggmap(ggmap = map0, darken = c(.5, "white")) +
    #monitoring area
    geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"),
            alpha=0.1,
            #reduce/eliminate outline
            lwd = 0.1, 
            show.legend = F
            ) +
    
    #annual averages
    geom_point(data=filter(annual_bins,
                           ufp_range_nm == ns_bin_range[i]
                           ),
             aes(x=longitude, y=latitude, col=value), 
             inherit.aes = F, size=2)  +
    scale_color_gradient(name = "Conc",
                        low = "yellow", high = "red",
                        ) +
    facet_wrap(~ufp_range_nm)  + 
    # # add scale & N arrow to top rught
    # annotation_scale(location = "tr") +
    # annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +
    # 
    # annotation_north_arrow(location = "tr",
    #                        #point towards North Pole
    #                        which_north = "true",
    #                        pad_y = unit(0.5, "in"),
    #                        style = north_arrow_fancy_orienteering
    #                        ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                                       )
                       ) +
    #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 1)
         ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
       ) 
  
  p[[i]]
  
  }

ggarrange(plotlist = p#, #ncol = 3, nrow = 2
          )


#ggsave(file.path(image_path, "map_ufp_bin_ns.png"),  height = 13, width = 11)


```






"total pollution map" 

* using NanoScan UFP measures (10-420 nm) 

 
$$
Total\ Scaled\ Conc\ at\ a\ Site= \frac{1}{n} \sum_{i=1}^{n} (X_{i,j} - mean(X_i))/SD(X_i)
$$

Where $n$ is each individual pollutant, and $j$ is each individual pollutant measurement


```{r}
  
total_pollution <- annual %>%
  #only keep 1 UFP measure
  filter(!(grepl("UFP", pollutant) & ufp_range_nm != "20-1,000")) %>%
  
  group_by(variable) %>%
  #standardize pollutant values
  mutate(#value = scale(value),
         value = (value-median(value))/IQR(value)
         ) %>% #View()
  # calculate "total" AP at any given site. #made sure that all sites had all 5 AP measures before doing this
  group_by(location, site, longitude, latitude) %>%
  summarize(
    max_p = unique(pollutant)[value==max(value)],
    value = sum(value)
    )
  

# map

print("Total air pollution based on standardized values ([x-mean]/SD)")

pt_size <- 3.5

ggmap(ggmap = map0, darken = c(.5, "white")) +
  #monitoring area
  geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(
    fill = "Monitoring Area"), 
    alpha=0.1, lwd = 0.1) +
  
  #airport
  geom_point(aes(y=47.441, x=-122.303, #shape="Sea-Tac\nAirport"
                 ), size=pt_size+3,  
             #shape=11
             shape=22 #"A"
             ) +
  
  #annual averages
  ## background
  geom_point(data=total_pollution, aes(x=longitude, y=latitude, shape=max_p),
             inherit.aes = F, size=pt_size+0.5)  +
  ## actual value
  geom_point(data=total_pollution, aes(x=longitude, y=latitude, 
                                       col=value, #fill = value,
                                       shape=max_p), 
           inherit.aes = F, size=pt_size)  +
  
  
  scale_shape_manual(values=c(15, 16, 17, 18, 10#, 11
                              )) +
  #scale_shape_manual(values=c(21:25)) +
  scale_color_gradient2(name = "Total Scaled\nAir Pollution", 
                        #low = "black", mid = "azure", high = "red",
                        #low = "azure", mid = "gray", high = "black",
                        high = "red", low = "blue", #mid = "yellow",
                        #midpoint = 0
                        ) +
    # add scale & N arrow to top rught
  annotation_scale(location = "tr", unit_category ="metric") +
  annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +
    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank(),
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1, nsmall = 1)
                       ) +
  #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 3),
         shape = guide_legend(order = 1)
         ) +
  #add attribution/reference to bottom left
    geom_text(aes(x=-Inf, y=-Inf, hjust=-0.01, vjust=-0.3,
                label= "Map tiles by Stamen Design, under CC BY 3.0. \nData by OpenStreetMap, under ODbL."
                ),
            size=2.5
            ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = "",
       shape = "Leading Pollutant"
       ) 


ggsave(file.path(image_path, "map_total_ap.png"),  height = 13, width = 11)

```


```{r, eval=F}
# we expect that smaller bin sizes will generally have higher particle counts (see boxplots above). What we want to know is whether there are places with higher/lower than average concentrations of specific UFP bin sizes. These relatively elevated levels may be related to specific sources (e.g., airport, rail yard). We will thus also scale UFP bin counts like we did above with the multipollutant map.
# 
# * map shows that the UFP concentrations and particle size compositions differ at different locations  

total_ufp_pollution <- annual_bins %>%
  filter(ufp_range_nm %in% ns_bin_range) %>%
  group_by(ufp_range_nm #variable
           ) %>%
  #standardize pollutant values
  mutate(value = scale(value)) %>% #View()
  # calculate "total" UFP at any given site. 
  group_by(location, site, longitude, latitude) %>%
  summarize(
    max_p = unique(ufp_range_nm)[value==max(value)],
    value = sum(value)
    )
  

# map

print("Total scaled UFP based on bin-specific standardized values ([x-mean]/SD) from the NanoScan.")

ggmap(ggmap = map0, darken = c(.5, "white")) +
  #monitoring area
  geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(
    fill = "Monitoring Area"), 
    alpha=0.1, lwd = 0.1) +
  #annual averages
  geom_point(data=total_ufp_pollution, aes(x=longitude, y=latitude, 
                                       col=value,  
                                       shape=max_p), 
           inherit.aes = F, size=4)  +
  
  #scale_shape_manual(values=c(15, 16, 17, 18, 10)) +
  
  scale_shape_manual(values=c(1:length(ns_bin_range))) +
  scale_color_gradient2(name = "Total Scaled\nUFP",
                        high = "red", low = "blue", #mid = "yellow",
                        ) +
    # add scale & N arrow to top rught
  annotation_scale(location = "tr", unit_category ="metric") +
  annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +
    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank(),
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1, nsmall = 1)
                       ) +
  #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 3),
         shape = guide_legend(order = 1)
         ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = "",
       shape = "Leading Size (nm)"
       ) 


ggsave(file.path(image_path, "map_ufp_bin.png"),  height = 13, width = 11)

```



## Lasso

```{r}

# fn runs lasso and returns a list: a) covariate estimates: b) lambda

lasso_fn <- function(dt, x_names, y_name, family. = "gaussian", lambda. = "") {
  
  pacman::p_load(glmnet)
  
  x <- model.matrix(as.formula(paste(y_name, "~", 
                                     paste(x_names, collapse = " + "))
  ), dt)[, -1]
  
  #replace y "name" w/ actual data
  y <- dt[[y_name]]   
  
  #select lambda through CV if not supplied
  if(lambda. == ""){
    cv.out <- cv.glmnet(x = x,
                        y = y, 
                        alpha=1, 
                        family= family., 
                        standardize=T)
    
    lambda. <- cv.out$lambda.min
  }
  
  # run Lasso
  lasso.m <- glmnet(x = x,
                    y = y, 
                    alpha = 1, 
                    family= family.,  
                    standardize = T)
  
  #save coefficient estimates
  lasso_coef <- predict(lasso.m, 
                        type= "coefficients",  
                        s= lambda.)[1:(ncol(x)+1),] %>%
    as.data.frame() %>%
    rownames_to_column() %>%
    rename(cov = rowname,
           coef = ".") %>%
    #keep coefficients that are not 0 or intercept values
    filter(coef != 0,
           cov != "(Intercept)")
  
  
  results <- list(results = lasso_coef,
                  lambda = lambda.
  )
  
  return(results)
  
}

```

```{r}
# function labels covariates 

split_cov_name <- function(dt, cov) {
  dt <- suppressWarnings(dt %>%
                           rename(cov_full_name = cov) %>%
                           mutate(
                             Buffer = substr(cov_full_name, nchar(cov_full_name)-4, nchar(cov_full_name)),
                             #for non-buffered covariates, use "0"
                             Buffer = as.numeric(ifelse(!is.na(as.integer(Buffer)), Buffer, 0)),
                             #drop buffer repetition
                             cov = ifelse(Buffer==0, cov_full_name, substr(cov_full_name, 1, nchar(cov_full_name)-5) )
                           )
  ) %>%
    select(contains("cov"), Buffer, everything())
  
    # elevation
    dt$cov[grepl("^elev_.+_above$", dt$cov_full_name)] <- "elev_above"
    dt$cov[grepl("^elev_.+_below$", dt$cov_full_name)] <- "elev_below"
    dt$cov[grepl("^elev_.+_stdev$", dt$cov_full_name)] <- "elev_stdev"
    dt$cov[grepl("^elev_.+_at_elev$", dt$cov_full_name)] <- "elev_at_elev"
    
    dt$Buffer[grepl("_1k_", dt$cov_full_name)] <- 1000
    dt$Buffer[grepl("_5k_", dt$cov_full_name)] <- 5000
    
  return(dt)
}
```

table of covariates used

```{r}
geo_t <- read_csv(file.path("~", "Documents", "School", "PhD", "Dissertation", "TRAP R Project", "Output", "Aim 2", "Tables", "0. Geocovariates", "cov_descrip.csv")) %>%
  #only include 2010 pop density
  filter(!Covariate %in% c("pop_s", "pop90_s"))

geo_t %>%
  rename(Category = Kind) %>%
  kable(caption = "Available geographic covariates (geocovariates) at monitoring sites.",
    row.names = T) %>%
  kable_styling() #%>% add_footnote("see MESA DOOP for additional details") 
  
```


```{r}
cov_names <- str_subset(names(geo), "site_id|native_id|lambert|latitude|longitude|pop_|pop90_", T)

annual_geo <- left_join(annual, geo, by=c("location" = "native_id"))

## for bins
annual_bins_geo <- left_join(annual_bins, geo, by=c("location" = "native_id")) %>%
  filter(variable != "median")

# run lasso for each pollutant
lms0 <- annual_geo %>%
  group_by(pollutant, ufp_range_nm) %>%
  nest() %>%
  mutate(
    lm = map(data, ~lasso_fn(dt = .x, x_names = cov_names, y_name = "value")),
  ) %>% 
  unnest(lm) %>% unnest(lm) %>%
  select(-c(data)) %>%
  rename(lambda = lm) %>%
  split_cov_name(cov = "cov") %>%
  # ? NAs ?
  drop_na(coef) 

#only show top covariates
keep_covars <- 10


lms <- lms0 %>%
  group_by(pollutant, ufp_range_nm) %>%
  arrange(desc(abs(coef))) %>% 
  slice(1:keep_covars)

```


### --> start here 


```{r, fig.height=10}
# all pollutants
my.alpha <- 1

print("Lasso regression coefficient estimates for Annual Average pollutant Concentrations. Empty circles represent buffered covariates, while dots represent other covariates such as proximity.")

lms %>%
  ggplot(aes(x = coef, y = cov, col=ufp_range_nm)) +
  geom_point(aes(size=Buffer),
             shape=1,
             alpha=my.alpha) +
  geom_point(data = filter(lms, Buffer==0)) +
  geom_vline(xintercept=0, linetype=2, alpha=my.alpha) +
    facet_wrap(~pollutant, scales = "free_x", 
               nrow = 1
               ) +
  labs(y = "Geocovariate",
       x = "Coefficient Estimate",
       shape= "non-buffer", 
       col = "UFP Size (nm)"
       ) +
  theme(legend.position = "bottom",
        axis.text.y = element_text(size=12, #face="bold"
                                   ),    
        ) #+ theme_grey()


ggsave(file.path(image_path, "lasso.png"), height = 11, width = 10)

```

### --> why are some lms empty for some bins???

### --> delete this here? 

```{r}
## for bins
lms_bins0 <- annual_bins_geo %>%
  group_by(Instrument = instrument, ufp_range_nm) %>%
  nest() %>%
  mutate(
    lm = map(data, ~lasso_fn(dt = .x, x_names = cov_names, y_name = "value")),
  ) %>% 
  unnest(lm) %>% unnest(lm) %>%
  select(-c(data)) %>%
  rename(lambda = lm) %>%
  split_cov_name(cov = "cov") %>%
  # ? NAs ?
  drop_na(coef)
 

#keep_covars_less <- 5

lms_bins <- lms_bins0 %>%
  mutate(ufp_range_nm = factor(ufp_range_nm, levels = c(ns_bin_range, ptrak_bin_range))) %>%
  group_by(Instrument, ufp_range_nm) %>%
  arrange(desc(abs(coef))) %>% 
  slice(1:keep_covars)

```


### --> "237.1-316.2" bin is missing. Is it b/c only 223 sites have annual average for these bins? The largest bin has 281. All other bins have 309 sites. 

```{r, fig.height=10, eval=F}

lms_bins %>%
  ggplot(aes(x = coef, y = cov, col=ufp_range_nm)) +
  geom_point(aes(size=Buffer, #shape=Instrument
                 ),
             shape=1,
             alpha=my.alpha) +
  geom_point(data = filter(lms_bins, Buffer==0)) +
  #scale_shape_manual(values=c(1,2)) +
  #keep these on the same scales
  facet_wrap(~Instrument, scales="free_x") +
  geom_vline(xintercept=0, linetype=2, alpha=my.alpha) +
  labs(y = "Geocovariate",
       x = "Coefficient Estimate",
       col = "UFP\nSize\nRange (nm)"
       ) +
  theme(legend.position = "bottom") +
  #make NS and PTRAK colors look different 
  scale_color_manual(values= c(rainbow_hcl(12), rainbow_hcl(2))) +
  theme(
    axis.text.y = element_text(size=12, #face="bold"
                                   ),  
  )

 
ggsave(file.path(image_path, "SI", "lasso_bins0.png"), height = 11, width = 12)

```


### --> "237.1-316.2" bin is missing. Is it b/c only 223 sites have annual average for these bins? The largest bin has 281. All other bins have 309 sites. 

* alternative to abvoe    
  * each bin has it's own scale since larger bins are associated with lower concentrations and so coefficient estimates are much smaller than those for smaller bins    
  * easier to see the many NS bins  

```{r, fig.height=6}
# each bin and instrument has its own facet

for(i in seq_along(bin_instruments)) {
#i=2
  p <- lms_bins %>%
    filter(Instrument == bin_instruments[i]) %>%
    ggplot(aes(x = coef, y = cov, #col=ufp_range_nm
               )) +
    # don't need to show color legend
    scale_color_discrete(guide = FALSE) +
    
    geom_point(aes(size=Buffer),
             shape=1,
             alpha=my.alpha) +
    geom_point(data = filter(lms_bins, Buffer==0, 
                             Instrument == bin_instruments[i])) +
    facet_wrap(Instrument~ufp_range_nm, scales = "free_x") +
    geom_vline(xintercept=0, linetype=2, alpha=my.alpha) +
    labs(y = "Geocovariate",
         x = "Coefficient Estimate",
         col = "UFP\nSize\nRange (nm)"
         ) +
    theme(legend.position = "bottom")  

  print(p)
  
  ggsave(file.path(image_path, "SI", paste0("lasso_bin_",bin_instruments[i], ".png")), height = 10, width = 8)
  
}


```

## UFPs by bin 


```{r, eval=F}
#- crude Nanoscan bin size


 # annual_bins %>% 
#   distinct(variable, ufp_range_nm)

ufp_bin_pctl <-annual_bins %>%
  filter(!variable %in% c("median", "pnc_20_36", "pnc_screen")) %>%
  mutate(variable = as.numeric(as.character(variable)),
         var_bin = ifelse(variable <= 48.7, "10-56.2",
                          ifelse(variable > 48.7 & variable <115.5, "56.2-100",
         # var_bin = ifelse(variable <= 36.5, "10-42.2",
         #                  ifelse(variable > 36.5 & variable <115.5, "42.2-100",
                                 ifelse(variable >= 115.5 & variable <=365.2, "100-421.7", NA
                                        ))),
         var_bin = factor(var_bin, levels = unique(var_bin))
         ) %>%
  group_by(var_bin) %>%
  mutate(
    value_percentile = fmsb::percentile(value),
    value_normalized = scale(value)
  )
  

 

# ns_bin2 <- unique(ufp_bin_pctl$var_bin)
# 
# p <- list()
# 
# for (i in seq_along(ns_bin2)) {
#   #i=1
  
  #p[[i]] <- 
    p1 <- ggmap(ggmap = map0, darken = c(.5, "white")) +
    #monitoring area
    geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"),
            alpha=0.1,
            #reduce/eliminate outline
            lwd = 0.1,
            ) +
    
    #annual averages
    geom_point(data=filter(ufp_bin_pctl, 
                           #var_bin == ns_bin2[i]
                           ),
             aes(x=longitude, y=latitude, col = value #col=value_percentile
                 ), 
             inherit.aes = F, size=2)  +
  scale_color_gradient(name = "Conc",
                       low = "yellow", high = "red",
                       ) +
    facet_wrap(~instrument+var_bin)  + 
    # add scale & N arrow to top rught
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank(),
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1, nsmall = 1)
                       ) +
  #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 1)) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
       ) 

    # p1
#  p[[i]] 
# }
# 
# ggarrange(plotlist = p)


#ggsave(file.path(image_path, "map_ufp_nanoscan.png"),  height = 8, width = 12)


```

-- ptrak bins

```{r, eval=F}

p2 <- ggmap(ggmap = map0, darken = c(.5, "white")) +
    #monitoring area
    geom_sf(data=monitoring_area_shp, inherit.aes = F, aes(fill = "Monitoring Area"),
            alpha=0.1,
            #reduce/eliminate outline
            lwd = 0.1, 
            show.legend = F
            ) +
    
    #annual averages
    geom_point(data=filter(annual_bins,
                           ufp_range_nm %in% ptrak_bin_range),
             aes(x=longitude, y=latitude, col=value), 
             inherit.aes = F, size=2)  +
    scale_color_gradient(name = "Conc",
                        low = "yellow", high = "red",
                        ) +
    facet_wrap(~instrument+ufp_range_nm)  + 
    # add scale & N arrow to top rught
    annotation_scale(location = "tr") +
    annotation_scale(location = "tr", unit_category ="imperial", pad_y = unit(0.55, "cm")) +

    annotation_north_arrow(location = "tr",
                           #point towards North Pole
                           which_north = "true",
                           pad_y = unit(0.5, "in"),
                           style = north_arrow_fancy_orienteering
                           ) +
  theme_bw() +
  theme(
    legend.justification=c(0,1),  
    legend.position=c(0,1),  
    legend.background =  element_blank()
    ) +
    coord_sf(expand = F) +
    scale_x_continuous(breaks = map_x_labels, labels = map_x_labels ) +
    scale_y_continuous(breaks = map_y_labels, 
                       labels = format(map_y_labels,digits = 1,
                                       nsmall = 1
                                       )
                       ) +
    #arrange legend order
  guides(col = guide_colorbar(order = 2),
              fill = guide_legend(order = 1)
         ) +
  labs(x = "Longitude",
       y = "Latitude",
       fill = ""
       ) 
  
#ggsave(file.path(image_path, "map_ufp_bin_ptrak.png"),  height = 6, width = 7)

```

```{r, eval=F}
ggarrange(p1, p2, nrow = 2) 

ggsave(file.path(image_path, "map_ufp_bins.png"),  height = 13, width = 9)

```







# Decay curves


```{r}
# annual_geo
# annual_bins_geo
density_covars <- readRDS(file.path("Data", "Output", "density_covars.rda"))  

df <- data.frame(var = density_covars, 
                 label = c("Meters to A1 Road",
                   "Meters to A1-A2 Intersection",
                   "Meters to Large Airport",
                   "Meters to Railyard",
                   "Meters to Large Port",
                   "Meters to Coast"
                   ), 
                 stringsAsFactors = F
                 )

for (i in seq_along(density_covars)) {
  #i=3
  
  p <- annual_geo %>%
    #put log distances on natural scale
    mutate_at(vars(df$var[i]), ~exp(.)) %>% #select(df$var[i]) %>% range()
    #rename for easier access
    rename(my_covar = df$var[i]) %>%
    #plot
    ggplot(aes(y=value, x = my_covar, col=ufp_range_nm)) + 
    facet_wrap(~pollutant, scales = "free_y") + 
    geom_point(alpha=0.5) + 
    geom_smooth() + 
      labs(x = df$label[i],
           y = "Value"
           )
  
  print(p)
  
  ggsave(file.path(image_path, "SI", "Decay Curves", 
                   paste0(substr(df$var[i], 5, nchar(df$var[i])), ".png")
                   ), 
         height = 11, width = 11)
  
  }

```

same as above but for UFP bins

```{r}

for (i in seq_along(density_covars)) {
  #i=1
  
  p <- annual_bins_geo %>%
    
    # ? do this?
    #filter(instrument == "P-TRAK") %>%
    
    #put log distances on natural scale
    mutate_at(vars(df$var[i]), ~exp(.)) %>% 
    #rename for easier access
    rename(my_covar = df$var[i]) %>%
    #plot
    ggplot(aes(y=value, x = my_covar, col=ufp_range_nm)) + 
    facet_wrap(~instrument, scales = "free_y") + 
    geom_point(alpha=0.3) +
  #make NS and PTRAK colors look different 
  scale_color_manual(values= c(rainbow_hcl(13), rainbow_hcl(2))) +
    
    geom_smooth(se=F
                ) + 
      labs(x = df$label[i],
           y = "Value",
           col = "UFP Range (nm)"
           ) 
  
  print(p)
  
  ggsave(file.path(image_path, "SI", "Decay Curves", "UFP Bins",
                   paste0(substr(df$var[i], 5, nchar(df$var[i])), ".png")
                   ),
         height = 11, width = 11)
  
  }

```




# Session Info

```{r}
#citation("ggmap")

sessionInfo()

```

```{r}
# save package references to reference manager #https://bookdown.org/yihui/rmarkdown-cookbook/write-bib.html
##1.
knitr::write_bib(c("broom", "colorspace", "cowplot", "fmsb", "forcats", "GGally", "ggpmisc", "ggpp", "ggpubr", "gstat", "knitr", "spData", "units" 
                   ), 
                 file = file.path("Data", "Output", "packages_v2.bib"))
##2. import this file into reference manager 

```




